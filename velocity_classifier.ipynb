{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"velocity_classifier.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"jdEKRZKFe32g","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p /content/drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-x8bta7wgPzc","colab_type":"code","colab":{}},"cell_type":"code","source":["cd drive/Team\\ Drives/Genre"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5m2vqq0Oghpq","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip uninstall keras\n","!pip install keras==2.0.8\n","!pip install matplotlib2tikz"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QXm7OalUghwp","colab_type":"code","colab":{}},"cell_type":"code","source":["cd recurrentshop/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B2fGSda9ghzS","colab_type":"code","colab":{}},"cell_type":"code","source":["!python setup.py install"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SpKJ_TJagh2W","colab_type":"code","colab":{}},"cell_type":"code","source":["cd ../"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ozBxkUn2gh4_","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","keras.__version__"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f238unBQgxlV","colab_type":"code","colab":{}},"cell_type":"code","source":["ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6hNpHYyJgxsq","colab_type":"code","colab":{}},"cell_type":"code","source":["# use big or small data\n","big = 1\n","\n","fil = open('data_folder_setting.py', 'w')\n","\n","if not big:\n","  fil.write('epochs = 2\\n')\n","  fil.write('source_folder = \\'data/JvP_small\\'\\n')  # folder of data\n","  fil.write('classes = [\\'Jazz\\', \\'Pop\\']\\n') # folder in source_folder\n","\n","# big data\n","if big:\n","  fil.write('epochs = 2000\\n')\n","  fil.write('source_folder = \\'data/JvP\\'\\n')  # folder of data\n","  fil.write('classes = [\\'Jazz\\', \\'Pop\\']\\n') # folder in source_folder\n","  #epochs = 2000\n","  #source_folder = 'data/JvP/'\n","  #classes = ['Jazz', 'Pop'] # folder in source_folder\n","fil.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ew0elaQTgxv2","colab_type":"code","colab":{}},"cell_type":"code","source":["from settings import *\n","from keras.models import Sequential\n","from keras import regularizers\n","from keras.layers import Input, RepeatVector\n","from keras.models import Model\n","from keras.layers.recurrent import LSTM, GRU\n","from keras.layers import TimeDistributed\n","from keras.layers import Dense, Activation\n","from keras.layers.embeddings import Embedding\n","from keras.optimizers import RMSprop, Adam\n","from keras.utils import to_categorical\n","from keras.layers.wrappers import Bidirectional\n","from random import shuffle\n","import progressbar\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import _pickle as pickle\n","import time\n","import utils.data_class as data_class\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import class_weight\n","\n","import tensorflow as tf\n","from keras.backend.tensorflow_backend import set_session\n","import pretty_midi as pm\n","import sys\n","\n","from matplotlib2tikz import save as tikz_save\n","\n","from utils.import_midi import import_midi_from_folder"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jj7xzRAzhg2-","colab_type":"code","colab":{}},"cell_type":"code","source":["# current data folder\n","print(epochs, source_folder, classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HcHhnlbSgxzR","colab_type":"code","colab":{}},"cell_type":"code","source":["save_plot = True\n","lstm_size = 256\n","batch_size = 512\n","learning_rate = 0.00002 #1e-06\n","step_size = 1\n","save_step = 10\n","shuffle_train_set = True\n","bidirectional = False\n","embedding = False\n","optimizer = 'Adam'\n","activity_regularizer = None\n","reset_states = True\n","num_layers = 2\n","test_step = 1\n","\n","scale_velocity_between_0_and_1 = False\n","\n","#wheter to set the velocity to 1 everywhere where it is > 1\n","#by comparing this test accuracy with the evaluation without this\n","# you can see how much influence the actual velocity info has\n","only_train_note_starts = False\n","#function that runs over V if only_train_note_starts\n","def set_to_1_if_nonzero(V):\n","    V_normalized = np.copy(V)\n","    for sample in range(V.shape[0]):\n","        for step in range(V.shape[1]):\n","            if V[sample, step,0] > 0:\n","                V_normalized[sample, step, 0] = 1\n","    return V_normalized\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2aF6iULJgx2z","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","print('loading data...')\n","# Get Train and test sets\n","\n","\n","folder = source_folder\n","\n","V_train, V_test, D_train, D_test, T_train, T_test, I_train, I_test, Y_train, Y_test, X_train, X_test, C_train, C_test, train_paths, test_paths = import_midi_from_folder(folder)\n","\n","train_set_size = len(X_train)\n","test_set_size = len(X_test)\n","\n","\n","print(len(train_paths))\n","print(len(test_paths))\n","print(C_test)\n","\n","\n","class_string = ''\n","for class_name in classes:\n","    class_string += class_name\n","\n","fd = {'highcrop': high_crop, 'lowcrop':low_crop, 'lr': learning_rate, 'opt': optimizer,\n","'bi': bidirectional, 'lstm_size': lstm_size, 'trainsize': train_set_size, \n","'testsize': test_set_size, 'input_length': input_length, 'reset_states': reset_states, \n","'num_layers':num_layers, 'only_train_note_starts': only_train_note_starts, \n","'velocity_threshold_such_that_it_is_a_played_note': velocity_threshold_such_that_it_is_a_played_note, \n","'scale': scale_velocity_between_0_and_1, 'classes': class_string}\n","t = str(int(round(time.time())))\n","model_name = t+'-num_layers_%(num_layers)s_maxlen_%(input_length)s_otns_%(only_train_note_starts)s_lstmsize_%(lstm_size)s_trainsize_%(trainsize)s_testsize_%(testsize)s_thresh_%(velocity_threshold_such_that_it_is_a_played_note)s_scale_%(scale)s_classes_%(classes)s' % fd\n","\n","model_path = model_path + model_name + '/'\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","\n","\n","# Define an input sequence and process it.\n","inputs = Input(shape=(None, input_dim))\n","lstm_outputs = inputs\n","for layer_no in range(num_layers-1):\n","    lstm_outputs = GRU(lstm_size, return_state=False, return_sequences=True)(lstm_outputs)\n","#last layer, that does not return sequences\n","lstm_outputs = GRU(lstm_size, return_state=False, return_sequences=False)(lstm_outputs)\n","dense = Dense(num_classes, activation='softmax')\n","outputs = dense(lstm_outputs)\n","model = Model(inputs, outputs)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-EjTzS8mgx59","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#compile autoencoder\n","if optimizer == 'RMS': optimizer = RMSprop(lr=learning_rate)\n","if optimizer == 'Adam': optimizer = Adam(lr=learning_rate)\n","loss = 'categorical_crossentropy'\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","\n","print(model.summary())\n","\n","# initialize loss arrays\n","total_test_loss_array = [] \n","total_test_accuracy_array = []\n","total_train_loss_array = []\n","total_train_loss = 0\n","total_train_accuracy_array = []\n","total_train_accuracy = 0\n","\n","\n","if scale_velocity_between_0_and_1:\n","    for V in (V_train + V_test):\n","        V[np.nonzero(V)] = (V[np.nonzero(V)] - velocity_threshold_such_that_it_is_a_played_note) / (1.0-velocity_threshold_such_that_it_is_a_played_note)\n","\n","if only_train_note_starts:\n","    for V in (V_train + V_test):\n","        V[np.nonzero(V)] = 1\n","\n","# Test function\n","def test(testID):\n","    print('\\nTesting:')\n","    total_test_loss = 0\n","    total_test_loss_length = 0\n","    total_test_loss_number = 0\n","\n","    confusion_matrix = np.zeros((num_classes, num_classes))\n","\n","    bar = progressbar.ProgressBar(max_value=test_set_size, redirect_stdout=False)\n","    for i, test_song in enumerate(X_test):\n","\n","        X = V_test[i]\n","        X = np.expand_dims(X, 2)\n","        num_samples = X.shape[0]\n","        c = C_test[i]\n","        Y = np.asarray([to_categorical(c, num_classes=num_classes)]*num_samples).squeeze()\n","\n","        scores = model.evaluate(X,Y , batch_size=batch_size, verbose=verbose)\n","        if reset_states:\n","            model.reset_states()\n","        total_test_loss += scores[0]\n","\n","        Y_predicted = model.predict(X, batch_size=batch_size, verbose=verbose)\n","        for y_val, y_predicted in zip(Y, Y_predicted):\n","            y_class_test = np.argmax(y_val)\n","            y_class_predicted = np.argmax(y_predicted)\n","            confusion_matrix[y_class_predicted, y_class_test] += 1\n","        bar.update(i+1)\n","\n","    accuracy = np.sum(np.diagonal(confusion_matrix)) / np.sum(confusion_matrix)\n","    total_test_loss_array.append(total_test_loss/test_set_size)\n","    total_test_accuracy_array.append(accuracy)\n","    print('\\nTotal test loss: ', total_test_loss/test_set_size)\n","    print('Total accuracy: ' + str(accuracy*100) + \"%\") \n","    print('-'*50)\n","    plt.figure()\n","    plt.title('Style classification on velocity information')\n","    plt.plot(total_test_loss_array, label='Total test loss')\n","    plt.plot(total_train_loss_array, label='Total train loss')\n","    plt.plot(total_test_accuracy_array, label='Total test accuracy')\n","    plt.plot(total_train_accuracy_array, label='Total train accuracy')\n","    plt.legend(loc='lower left', prop={'size': 8})\n","    if show_plot: plt.show()\n","    if save_plot: \n","        plt.savefig(model_path+t+'velocity_train.png')\n","        tikz_save(model_path+t+'velocity_train.tex', encoding='utf-8', show_info=False)\n","    pickle.dump(total_test_loss_array,open(model_path+'total_test_loss_array.pickle', 'wb'))\n","    pickle.dump(total_test_accuracy_array,open(model_path+'total_test_accuracy_array.pickle', 'wb'))\n","    pickle.dump(total_train_accuracy_array,open(model_path+'total_train_accuracy_array.pickle', 'wb'))\n","    pickle.dump(total_train_loss_array,open(model_path+'total_train_loss_array.pickle', 'wb'))\n","\n","    if testID % save_step is 0:\n","        confusion_matrix = confusion_matrix/confusion_matrix.sum(axis=1, keepdims=True)\n","        plt.figure()\n","        plt.imshow(confusion_matrix, interpolation='nearest')\n","        plt.title('Total accuracy: ' + str(accuracy) + '%')\n","        plt.ylabel('True label')\n","        plt.xlabel('Predicted label')\n","        plt.xticks(np.arange(0,num_classes), classes)\n","        plt.yticks(np.arange(0,num_classes), classes)\n","        plt.colorbar()\n","        if show_plot: plt.show()\n","        if save_plot: \n","            plt.savefig(model_path+'confusion_matrix' + str(testID) + '.png')\n","            tikz_save(model_path+'confusion_matrix' + str(testID) + '.tex', encoding='utf-8', show_info=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lF8PAq4-gx9S","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Save Parameters to text file\n","with open(model_path + 'params.txt', \"w\", encoding='utf-8') as text_file:\n","    text_file.write(\"velocity_threshold_such_that_it_is_a_played_note: %s\" % velocity_threshold_such_that_it_is_a_played_note + '\\n')\n","    text_file.write(\"epochs: %s\" % epochs + '\\n')\n","    text_file.write(\"train_set_size: %s\" % train_set_size + '\\n')\n","    text_file.write(\"test_set_size: %s\" % test_set_size + '\\n')\n","    text_file.write(\"only_train_note_starts: %s\" % only_train_note_starts + '\\n')\n","    text_file.write(\"learning_rate: %s\" % learning_rate + '\\n')\n","    text_file.write(\"save_step: %s\" % save_step + '\\n')\n","    text_file.write(\"shuffle_train_set: %s\" % shuffle_train_set + '\\n')\n","    text_file.write(\"test_step: %s\" % test_step + '\\n')\n","    text_file.write(\"bidirectional: %s\" % bidirectional + '\\n')\n","    text_file.write(\"load_from_pickle_instead_of_midi: %s\" % load_from_pickle_instead_of_midi + '\\n')\n","    text_file.write(\"pickle_load_path: %s\" % pickle_load_path + '\\n')\n","    text_file.write(\"train_paths: %s\" % train_paths + '\\n')\n","    text_file.write(\"test_paths: %s\" % test_paths + '\\n')\n","\n","# Train model\n","print('training model...')\n","for e in range(1, epochs+1):\n","\n","    total_train_loss = 0\n","    total_train_accuracy = 0\n","    \n","    print('Epoch ', e, 'of ', epochs, 'Epochs\\nTraining:')\n","\n","\n","    if shuffle_train_set:\n","\n","        permutation = np.random.permutation(len(X_train))\n","\n","        train_paths = [train_paths[i] for i in permutation]\n","        X_train = [X_train[i] for i in permutation]\n","        Y_train = [Y_train[i] for i in permutation]\n","        C_train = [C_train[i] for i in permutation]\n","        I_train = [I_train[i] for i in permutation]\n","        V_train = [V_train[i] for i in permutation]\n","        D_train = [D_train[i] for i in permutation]\n","        T_train = [T_train[i] for i in permutation]\n","\n","    bar = progressbar.ProgressBar(max_value=train_set_size)\n","    \n","    # Train model with each song seperately\n","    for i, train_song in enumerate(X_train):\n","\n","        X = V_train[i]\n","        X = np.expand_dims(X, 2)\n","        num_samples = X.shape[0]\n","\n","        if num_samples > 1:\n","            c = C_train[i]\n","            Y = np.asarray([to_categorical(c, num_classes=num_classes)]*num_samples).squeeze()\n","\n","\n","            hist = model.fit(X, Y,\n","                        epochs=1,\n","                        batch_size=batch_size,\n","                        shuffle=False,\n","                        verbose=verbose)\n","\n","            if reset_states:\n","                model.reset_states()\n","\n","            total_train_loss += np.mean(hist.history['loss'])\n","            total_train_accuracy += np.mean(hist.history['acc'])\n","        bar.update(i+1)\n","    if (e+1)%test_step is 0:\n","        total_train_loss = total_train_loss/train_set_size\n","        total_train_loss_array.append(total_train_loss)\n","        total_train_accuracy = total_train_accuracy/train_set_size\n","        total_train_accuracy_array.append(total_train_accuracy)\n","        test(e)\n","        \n","\n","    if e%save_step is 0:\n","        print('saving model')\n","        model_save_path = model_path + 'model' + 'Epoch' + str(e) + model_filetype\n","        model.save(model_save_path)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OYM6wbY1gyAw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}