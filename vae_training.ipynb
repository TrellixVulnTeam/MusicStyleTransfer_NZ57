{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae_training.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"uYY-hS-shTSs","colab_type":"code","outputId":"c58bffbf-891f-4bd3-8f12-58b900c60374","executionInfo":{"status":"ok","timestamp":1552427776895,"user_tz":300,"elapsed":1083,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!mkdir -p /content/drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"YjJzPGqAJicJ","colab_type":"code","outputId":"f7e48a6e-c067-4e3c-c74c-9e80ec11761f","executionInfo":{"status":"ok","timestamp":1552427778831,"user_tz":300,"elapsed":286,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["cd drive/Team\\ Drives/Genre"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/Team Drives/Genre'\n","/content/drive/Team Drives/Genre\n"],"name":"stdout"}]},{"metadata":{"id":"Rz4UM-xuJYHn","colab_type":"code","outputId":"ad83ae5f-7357-4846-c8d2-c42cd00e9053","executionInfo":{"status":"ok","timestamp":1552405787113,"user_tz":300,"elapsed":13797,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":615}},"cell_type":"code","source":["!pip uninstall keras\n","!pip install keras==2.0.8\n","!pip install matplotlib2tikz"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Uninstalling Keras-2.2.4:\n","  Would remove:\n","    /usr/local/lib/python3.6/dist-packages/Keras-2.2.4.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/docs/*\n","    /usr/local/lib/python3.6/dist-packages/keras/*\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.6/dist-packages/docs/md_autogen.py\n","    /usr/local/lib/python3.6/dist-packages/docs/update_docs.py\n","Proceed (y/n)? y\n","  Successfully uninstalled Keras-2.2.4\n","Collecting keras==2.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/3f/d117d6e48b19fb9589369f4bdbe883aa88943f8bb4a850559ea5c546fefb/Keras-2.0.8-py2.py3-none-any.whl (276kB)\n","\u001b[K    100% |████████████████████████████████| 276kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.11.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.14.6)\n","\u001b[31mtextgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.8 which is incompatible.\u001b[0m\n","Installing collected packages: keras\n","Successfully installed keras-2.0.8\n","Collecting matplotlib2tikz\n","  Downloading https://files.pythonhosted.org/packages/15/14/d051a016a97cbe6064f706012a0aa718dc2f7b6a3f217c66f7643e4c4df0/matplotlib2tikz-0.6.18-py2.py3-none-any.whl\n","Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib2tikz) (3.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from matplotlib2tikz) (1.14.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from matplotlib2tikz) (1.11.0)\n","Requirement already satisfied: Pillow>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib2tikz) (4.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->matplotlib2tikz) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->matplotlib2tikz) (2.5.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->matplotlib2tikz) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->matplotlib2tikz) (2.3.1)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=3.0.0->matplotlib2tikz) (0.46)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->matplotlib2tikz) (40.8.0)\n","Installing collected packages: matplotlib2tikz\n","Successfully installed matplotlib2tikz-0.6.18\n"],"name":"stdout"}]},{"metadata":{"id":"auS0FnrZJaMA","colab_type":"code","outputId":"96203439-ef50-4e2e-8bd1-4cdcdf94429f","executionInfo":{"status":"ok","timestamp":1552361669584,"user_tz":300,"elapsed":15799,"user":{"displayName":"Yubi Chen","photoUrl":"","userId":"02874515838556839493"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd recurrentshop/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/Team Drives/Genre/recurrentshop\n"],"name":"stdout"}]},{"metadata":{"id":"JoJpWox7Jboe","colab_type":"code","outputId":"6e77bc32-892f-4e8b-b9f8-af57cf6c1a97","executionInfo":{"status":"ok","timestamp":1552361676127,"user_tz":300,"elapsed":21419,"user":{"displayName":"Yubi Chen","photoUrl":"","userId":"02874515838556839493"}},"colab":{"base_uri":"https://localhost:8080/","height":1394}},"cell_type":"code","source":["!python setup.py install"],"execution_count":0,"outputs":[{"output_type":"stream","text":["running install\n","running bdist_egg\n","running egg_info\n","writing recurrentshop.egg-info/PKG-INFO\n","writing dependency_links to recurrentshop.egg-info/dependency_links.txt\n","writing requirements to recurrentshop.egg-info/requires.txt\n","writing top-level names to recurrentshop.egg-info/top_level.txt\n","reading manifest file 'recurrentshop.egg-info/SOURCES.txt'\n","writing manifest file 'recurrentshop.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/recurrentshop\n","creating build/bdist.linux-x86_64/egg/recurrentshop/backend\n","copying build/lib/recurrentshop/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/recurrentshop/backend\n","copying build/lib/recurrentshop/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/recurrentshop/backend\n","copying build/lib/recurrentshop/backend/__init__.py -> build/bdist.linux-x86_64/egg/recurrentshop/backend\n","copying build/lib/recurrentshop/advanced_cells.py -> build/bdist.linux-x86_64/egg/recurrentshop\n","copying build/lib/recurrentshop/cells.py -> build/bdist.linux-x86_64/egg/recurrentshop\n","copying build/lib/recurrentshop/basic_cells.py -> build/bdist.linux-x86_64/egg/recurrentshop\n","copying build/lib/recurrentshop/generic_utils.py -> build/bdist.linux-x86_64/egg/recurrentshop\n","copying build/lib/recurrentshop/__init__.py -> build/bdist.linux-x86_64/egg/recurrentshop\n","copying build/lib/recurrentshop/engine.py -> build/bdist.linux-x86_64/egg/recurrentshop\n","creating build/bdist.linux-x86_64/egg/backend\n","copying build/lib/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/backend\n","copying build/lib/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/backend\n","copying build/lib/backend/__init__.py -> build/bdist.linux-x86_64/egg/backend\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/backend/theano_backend.py to theano_backend.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/backend/tensorflow_backend.py to tensorflow_backend.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/backend/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/advanced_cells.py to advanced_cells.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/cells.py to cells.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/basic_cells.py to basic_cells.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/generic_utils.py to generic_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/recurrentshop/engine.py to engine.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/backend/tensorflow_backend.py to tensorflow_backend.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/backend/theano_backend.py to theano_backend.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/backend/__init__.py to __init__.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying recurrentshop.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying recurrentshop.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying recurrentshop.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying recurrentshop.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying recurrentshop.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/recurrentshop-1.0.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing recurrentshop-1.0.0-py3.6.egg\n","Copying recurrentshop-1.0.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding recurrentshop 1.0.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/recurrentshop-1.0.0-py3.6.egg\n","Processing dependencies for recurrentshop==1.0.0\n","Searching for Keras==2.0.8\n","Best match: Keras 2.0.8\n","Adding Keras 2.0.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for PyYAML==3.13\n","Best match: PyYAML 3.13\n","Adding PyYAML 3.13 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.11.0\n","Best match: six 1.11.0\n","Adding six 1.11.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for scipy==1.1.0\n","Best match: scipy 1.1.0\n","Adding scipy 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.14.6\n","Best match: numpy 1.14.6\n","Adding numpy 1.14.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for recurrentshop==1.0.0\n"],"name":"stdout"}]},{"metadata":{"id":"pCORR7p4JdmN","colab_type":"code","outputId":"a17a528f-bea5-4465-d115-f374652e9d97","executionInfo":{"status":"ok","timestamp":1552405793490,"user_tz":300,"elapsed":409,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd ../"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/Team Drives\n"],"name":"stdout"}]},{"metadata":{"id":"Oh9NkmMxiDxv","colab_type":"code","outputId":"3e40bb34-f5bc-42e7-f6b5-c7ad7e2b42cd","executionInfo":{"status":"ok","timestamp":1552405797964,"user_tz":300,"elapsed":3926,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["import keras\n","keras.__version__"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.0.8'"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"SocD0RDaGWPm","colab_type":"code","outputId":"8d16ce3c-8b40-4f40-cce5-2c075d04acbe","executionInfo":{"status":"ok","timestamp":1552405819465,"user_tz":300,"elapsed":1023,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["'Copy of settings.py'          README.md\n"," credentials.json              \u001b[0m\u001b[01;34mrecurrentshop\u001b[0m/\n"," \u001b[01;34mdata\u001b[0m/                         settings.py\n"," data_folder_setting.py        token.pickle\n"," Github.gdoc                   \u001b[01;34mutils\u001b[0m/\n"," instrument_classifier.ipynb   vae_definition.py\n"," LICENSE                       vae_evaluation.ipynb\n"," \u001b[01;34mmodels\u001b[0m/                       vae_evaluation.py\n"," \u001b[01;34mpickles\u001b[0m/                      vae_training.ipynb\n"," pitch_classifier.ipynb        vae_training.py\n"," \u001b[01;34m__pycache__\u001b[0m/                  velocity_classifier.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"DMagqUDAaXDD","colab_type":"code","colab":{}},"cell_type":"code","source":["# use big or small data\n","big = 1\n","\n","fil = open('data_folder_setting.py', 'w')\n","\n","if not big:\n","  fil.write('epochs = 1\\n')\n","  fil.write('max_songs = 20\\n')\n","  fil.write('source_folder = \\'data/JvP_small\\'\\n')  # folder of data\n","  fil.write('classes = [\\'Jazz\\', \\'Pop\\']\\n') # folder in source_folder\n","\n","# big data\n","if big:\n","  fil.write('epochs = 100\\n')\n","  fil.write('max_songs = 100\\n')\n","  fil.write('source_folder = \\'data/JvP\\'\\n')  # folder of data\n","  fil.write('classes = [\\'Jazz\\', \\'Pop\\']\\n') # folder in source_folder\n","  #epochs = 2000\n","  #source_folder = 'data/JvP/'\n","  #classes = ['Jazz', 'Pop'] # folder in source_folder\n","fil.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U13ACm9vnPCv","colab_type":"code","colab":{}},"cell_type":"code","source":["# ----------------------------------------------------------------------------------------------\n","# Import dependencies\n","# ----------------------------------------------------------------------------------------------\n","\n","from settings import *\n","from keras.utils import to_categorical\n","from random import shuffle\n","import progressbar\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import os\n","import numpy as np\n","import _pickle as pickle\n","import time\n","import vae_definition\n","from vae_definition import VAE\n","import tensorflow as tf\n","from keras.backend.tensorflow_backend import set_session\n","from sklearn.utils import class_weight\n","from sklearn.model_selection import train_test_split\n","import pretty_midi as pm\n","import sys\n","from utils.import_midi import import_midi_from_folder\n","import utils.data_class as data_class\n","from matplotlib2tikz import save as tikz_save\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vcNv3JSqUfLp","colab_type":"code","outputId":"6e43fa39-0c44-49f8-df7f-f40d30907289","executionInfo":{"status":"ok","timestamp":1552427786533,"user_tz":300,"elapsed":194,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# current data folder\n","print(epochs, source_folder, classes, max_songs)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["100 data/JvP ['Jazz', 'Pop'] 100\n"],"name":"stdout"}]},{"metadata":{"id":"66RnOeqgHQU4","colab_type":"code","colab":{}},"cell_type":"code","source":["# ----------------------------------------------------------------------------------------------\n","# Set parameters for training session (not for VAE)\n","# ----------------------------------------------------------------------------------------------\n","\n","# Path where the polyphonic models are saved:\n","model_path = 'models/autoencode/vae/'\n","model_filetype = '.pickle'\n","\n","assert(output_length > 0)\n","assert(input_length > 0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h_hSPofdxb44","colab_type":"code","outputId":"a7e2b178-e5f4-4d49-8aeb-1ba88ebe59fc","executionInfo":{"status":"ok","timestamp":1552406047909,"user_tz":300,"elapsed":216358,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":3539}},"cell_type":"code","source":["# ----------------------------------------------------------------------------------------------\n","# Import and preprocess data\n","# ----------------------------------------------------------------------------------------------\n","\n","print('loading data...')\n","# Get Train and test sets\n","\n","\n","folder = source_folder\n","# Y is target note\n","# V is velocity roll\n","# D is held_note_roll\n","V_train, V_test, D_train, D_test, T_train, T_test, I_train, I_test, Y_train, Y_test, X_train, X_test, C_train, C_test, train_paths, test_paths = import_midi_from_folder(folder)\n","\n","train_set_size = len(X_train)\n","test_set_size = len(X_test)\n","\n","\n","print(len(train_paths))\n","print(len(test_paths))\n","print(C_test)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["loading data...\n","Importing Jazz song called moonlight_becomes_you_bl.mid\n","Importing Jazz song called smile_rl.mid\n","Importing Jazz song called that_sunday_that_summer-kar_db.mid\n","Importing Jazz song called a_string_of_pearls-rev_gw.mid\n","Importing Jazz song called harbor_lights_platters_rs.mid\n","Importing Jazz song called this_masquerade-GB-LR_oz.mid\n","Importing Jazz song called breakout_39gm-swing-out-sister_ps.mid\n","Importing Jazz song called ive_got_the_world_on_a_string-R2_gw.mid\n","Importing Jazz song called cant_we_be_friends-1929-kar_jpp.mid\n","Importing Jazz song called between_the_sheets_mellod.mid\n","Importing Jazz song called our_love_is_here_to_stay_ccm.mid\n","Importing Jazz song called saturday_night-1944-kar_jpp.mid\n","Importing Jazz song called it_takes_too_long-to_learn_to_live_alone-Eydie-Gorme-kar_rt.mid\n","Importing Jazz song called the_mta-the_kingston_trio-kar_rt.mid\n","Importing Jazz song called elmira_st_boogie_gr (1).mid\n","Importing Jazz song called siempre_hay_esperanza_jk.mid\n","Importing Jazz song called saving_all_my_love_lr.mid\n","Importing Jazz song called tropic_twilight_lg.mid\n","Importing Jazz song called time_after_time_dm.mid\n","Importing Jazz song called good_bait_dm.mid\n","Importing Jazz song called lady_be_good_jh.mid\n","Importing Jazz song called gone_with_the_wind_dm.mid\n","Importing Jazz song called moonlighting-the-rippingtons-andres-chait.mid\n","Importing Jazz song called in_a_mellow_tone_djl.mid\n","Importing Jazz song called love_story-kar_js.mid\n","Importing Jazz song called paradise_cafe_gr_kar.mid\n","Importing Jazz song called choo_choo_ch_boogie-Louis-Jordan_dc.mid\n","Importing Jazz song called blue_bossa-kenny-dorham_dz.mid\n","Importing Jazz song called rhythm_and_romance-1935-kar_jpp.mid\n","Importing Jazz song called old_devil_moon-pt_dm.mid\n","Importing Jazz song called the_gypsy_in_my_soul-kar_jpp.mid\n","Importing Jazz song called after_the_fall-Incognito_ddj.mid\n","Importing Jazz song called takin_my_time_rmb.mid\n","Importing Jazz song called catch_a_falling_star-PComo_ap2.mid\n","Importing Jazz song called modus_interruptus-Org_ee.mid\n","Importing Jazz song called they_all_laughed-1936-Gershwin-ks_jpp.mid\n","Importing Jazz song called superstar_ccm.mid\n","Importing Jazz song called almost_like_being_in_love_gw.mid\n","Importing Jazz song called georgia_on_my_mind_bm.mid\n","Importing Jazz song called atlanta_ga-Woody-Herman-kar_r2_rt.mid\n","Importing Jazz song called tank_canny.mid\n","Importing Jazz song called golden_lady_rex.mid\n","Importing Jazz song called lullaby_of_birdland_rs.mid\n","Importing Jazz song called letter_from_home-pat-metheny_ht2.mid\n","Importing Jazz song called born_to_be_blue_mw.mid\n","Importing Jazz song called 500_miles_high-Chick-Corea_ee.mid\n","Importing Jazz song called jamf_rc.mid\n","Importing Jazz song called one_in_a_million_jm.mid\n","Importing Jazz song called the_color_of_my_love_jlh.mid\n","Importing Jazz song called misty_dc.mid\n","Importing Jazz song called if_i_were_a_bell-pt_dm.mid\n","Importing Jazz song called think_twice-celine-dion_th.mid\n","Importing Jazz song called santa_barbara_beach_dz.mid\n","Importing Jazz song called memories_of_you_jh.mid\n","Importing Jazz song called in_aeternum-org_sn.mid\n","Importing Jazz song called blues_in_f_sharp_bm.mid\n","Importing Jazz song called indian_summer_mw.mid\n","Importing Jazz song called lady_is_a_tramp_mw.mid\n","Importing Jazz song called ask_me_now-2piano-duet_dm.mid\n","Importing Jazz song called how_do_you_keep_the_music_playing_jlh.mid\n","Importing Jazz song called bach_variations_sn.mid\n","Importing Jazz song called bellavia-Mangione_ee.mid\n","Importing Jazz song called a_lovely_way_to_spend_an_evening-1943-Vs2-kar_jpp (1).mid\n","Importing Jazz song called dont_know_why-Norah-Jones-kar_ccm.mid\n","Importing Jazz song called just_friends_lg.mid\n","Importing Jazz song called come_rain_or_come_shine-woody_gw.mid\n","Importing Jazz song called georgia_pw.mid\n","Importing Jazz song called our_day_will_come_dan_west_dw-hd3.mid\n","Importing Jazz song called frenesi_artie-shaw1941_mw.mid\n","Importing Jazz song called flip_flop_and_fly_wc.mid\n","Importing Jazz song called birdland_bl2.mid\n","Importing Jazz song called moonlight-KennyG_pw.mid\n","Importing Jazz song called smooth_operator_cg.mid\n","Importing Jazz song called swing_swing_swing_1941_gw.mid\n","Importing Jazz song called brazilian_suite-Michel-Pertrucciani_dm.mid\n","Importing Jazz song called freedom_at_midnight-David-Benoit_dz.mid\n","Importing Jazz song called consolation_am.mid\n","Importing Jazz song called fever_bz2.mid\n","Importing Jazz song called a_lovely_way_to_spend_an_evening-1943-Vs2-kar_jpp.mid\n","Importing Jazz song called chans_song-Never-Said-Herbie-Hancock_bg2.mid\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n","  RuntimeWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Importing Jazz song called i_thought_about_you_dm.mid\n","Importing Jazz song called fly_by_night_rmb.mid\n","Importing Jazz song called always_rs-1.mid\n","Importing Jazz song called sing_sing_sing_prima_3x-gw.mid\n","Importing Jazz song called mc_modal_midi-Org_ee.mid\n","Importing Jazz song called black_orpheus_jh.mid\n","Importing Jazz song called romantic_dreams_pw.mid\n","Importing Jazz song called bossa_nova_usa_dwb.mid\n","Importing Jazz song called fools_rush_in_mw.mid\n","Importing Jazz song called maracangalha_sn.mid\n","Importing Jazz song called i_wish_you_love03_jlh.mid\n","Importing Jazz song called rum_n_coca_cola-andrews-sisters1945_ab.mid\n","Importing Jazz song called steppin_out-Joe-Jackson_eb.mid\n","Importing Jazz song called tico_tico_bh2.mid\n","Importing Jazz song called the_more_i_see_you-1945-v2-kar_jpp.mid\n","Importing Jazz song called im_old_fashioned-v1_dm.mid\n","Importing Jazz song called st_thomas-Sonny-Rollins_gt.mid\n","Importing Jazz song called count_on_him_jc.mid\n","Importing Jazz song called eye_of_the_beholder-chic-corea_rg.mid\n","Importing Jazz song called night_train_gw.mid\n","Importing Pop song called you_go_to_my_head_mw.mid\n","Importing Pop song called Barry_Manilow_-_Mandy.mid\n","Importing Pop song called Helen_Reddy_-_Aint_No_Way_to_Treat_a_Lady.mid\n","Importing Pop song called The_Go-Go's_-_Vacation.mid\n","Importing Pop song called Bee_Gees_-_You_Should_Be_Dancin'.mid\n","Importing Pop song called Everclear_-_Everything_To_Everyone.mid\n","Importing Pop song called Aretha_Franklin_-_Respect.mid\n","Importing Pop song called Dionne_Warwick_-_That's_What_Friends_Are_For.mid\n","Importing Pop song called Carole_King_-_So_Far_Away.mid\n","Importing Pop song called Paul_McCartney_-_Monkberry_Moon_Delight.mid\n","Importing Pop song called Paul_McCartney_-_Ebony_and_Ivory.mid\n","Importing Pop song called Semisonic_-_Closing_Time.mid\n","Importing Pop song called ABBA_-_SOS.mid\n","Importing Pop song called Blur_-_Ecco_Song.mid\n","Importing Pop song called Leif_Garrett_-_I_Was_Made_for_Dancin.mid\n","Importing Pop song called Gilbert_O_Sullivan_-_Claire.mid\n","Importing Pop song called Smashmouth_-_Walking_On_The_Sun.mid\n","Importing Pop song called Toni_Braxton_-_Breathe_Again.mid\n","Importing Pop song called Usher_-_My_Way.mid\n","Importing Pop song called En_Vogue_-_My_Lovin.mid\n","Importing Pop song called Stevie_Wonder_-_Signed_Sealed_Delivered.mid\n","Importing Pop song called Aqua_-_Barbie_Girl.mid\n","Importing Pop song called Boyzone_-_Picture_Of_You.mid\n","Importing Pop song called The_Carpenters_-_Close_to_You.mid\n","Importing Pop song called The_Corrs_-_Closer.mid\n","Importing Pop song called Chaka_Khan_-_Tell_Me_Something_Good.mid\n","Importing Pop song called Desree_-_Kissing_You.mid\n","Importing Pop song called New_Vaudeville_Band_-_Winchester_Cathedral.mid\n","Importing Pop song called The_Supremes_-_I_Hear_A_Symphony.mid\n","Importing Pop song called Phil_Collins_-_In_the_Air_Tonight.mid\n","Importing Pop song called Kenny_Loggins_-_Danger_Zone.mid\n","Importing Pop song called The_Corrs_-_Intimacy.mid\n","Importing Pop song called The_Monkees_-_I'm_Not_Your_Stepping_Stone.mid\n","Importing Pop song called The_Supremes_-_I'm_Gonna_Make_You_Love_Me.mid\n","Importing Pop song called Celine_Dion_-_Immortality.mid\n","Importing Pop song called M2M_-_Dont_Say_You_Love_Me.mid\n","Importing Pop song called Carly_Simon_-_Attitude_Dancing.mid\n","Importing Pop song called Bee_Gees_-_To_Love_Somebody.mid\n","Importing Pop song called Steely_Dan_-_Black_Friday.mid\n","Importing Pop song called Boyzone_-_A_Different_Beat.mid\n","Importing Pop song called Kenny_Loggins_-_Forever.mid\n","Importing Pop song called Herb_Alpert_-_Rise.mid\n","Importing Pop song called Celine_Dion_-_I'm_Your_Angel.mid\n","Importing Pop song called Harry_Nilsson_-_Without_You.mid\n","Importing Pop song called Sting_-_If_I_Ever_Lose_My_Faith_in_You.mid\n","Importing Pop song called Tony_Orlando_-_Knock_Three_Times.mid\n","Importing Pop song called The_Supremes_-_Baby_Love.mid\n","Importing Pop song called Mamas_and_Papas_-_California_Dreamin'.mid\n","Importing Pop song called Celine_Dion_-_All_By_Myself.mid\n","Importing Pop song called Ace_of_Base_-_Beautiful_Life.mid\n","Importing Pop song called when_sunny_gets_blue_bm.mid\n","Importing Pop song called The_Commodores_-_Nightshift.mid\n","Importing Pop song called Backstreet_Boys_-_Show_Me_the_Meaning.mid\n","Importing Pop song called Bee_Gees_-_Night_Fever.mid\n","Importing Pop song called Frankie_Valli_-_Cant_Take_My_Eyes_Off_Of_Yo.mid\n","Importing Pop song called Verve_-_Bitter_Sweet_Symphony.mid\n","Importing Pop song called The_Corrs_-_Remember.mid\n","Importing Pop song called The_Everly_Brothers_-_Cathy's_Clown.mid\n","Importing Pop song called Billy_Joel_-_It's_Still_Rock_and_Roll_to_Me.mid\n","Importing Pop song called Earth_Wind_and_Fire_-_September.mid\n","Importing Pop song called Bobby_Vinton_-_My_Special_Angel.mid\n","Importing Pop song called Phil_Collins_-_Sussudio.mid\n","Importing Pop song called Boyz_2_Men_-_Yesterday.mid\n","Importing Pop song called Neil_Diamond_-_Solitary_Man.mid\n","Importing Pop song called Simon_and_Garfunkel_-_Feelin'_Groovy.mid\n","Importing Pop song called Harry_Belafonte_-_Banana_Boat.mid\n","Importing Pop song called ABBA_-_The_Winner_Takes_It_All.mid\n","Importing Pop song called Spice_Girls_-_Goodbye.mid\n","Importing Pop song called Blackstreet_-_No_Diggity.mid\n","Importing Pop song called you_stepped_out_of_a_dream-Kahn-n-Brown_dm.mid\n","Importing Pop song called Bruce_Hornsby_-_Mandolin_Wind.mid\n","Importing Pop song called James_Taylor_-_Carolina_in_My_Mind.mid\n","Importing Pop song called Whitney_Houston_-_My_Love_Is_Your_Love.mid\n","Importing Pop song called Eagle_Eye_Cherry_-_Save_Tonight.mid\n","Importing Pop song called George_Benson_-_Give_Me_the_Night.mid\n","Importing Pop song called Billy_Joel_-_Big_Shot.mid\n","Importing Pop song called Bill_Withers_-_Aint_No_Sunshine.mid\n","Importing Pop song called The_Association_-_Never_My_Love.mid\n","Importing Pop song called Janet_Jackson_-_Escapade.mid\n","Importing Pop song called Bette_Midler_-_The_Wind_Beneath_My_Wings.mid\n","Importing Pop song called Lionel_Richie_-_Truly.mid\n","Importing Pop song called OMC_-_How_Bizarre.mid\n","Importing Pop song called Paul_McCartney_-_Jet.mid\n","Importing Pop song called Weezer_-_Undone_The_Sweater_Song.mid\n","Importing Pop song called Steely_Dan_-_My_Old_School.mid\n","Importing Pop song called Oasis_-_Whatever.mid\n","Importing Pop song called N_Sync_-_Tearing_Up_My_Heart.mid\n","Importing Pop song called Spice_Girls_-_Naked.mid\n","Importing Pop song called Destinys_Child_-_Say_My_Name.mid\n","Importing Pop song called Michael_Jackson_-_Don't_Stop_Till_You_Get_Enough.mid\n","Importing Pop song called Westlife_-_Fool_Again.mid\n","Importing Pop song called Bonnie_Tyler_-_It's_a_Heartache.mid\n","Importing Pop song called Jamiroquai_-_Alright.mid\n","Importing Pop song called Natalie_Imbruglia_-_Smoke.mid\n","Importing Pop song called Gino_Vannelli_-_I_Just_Wanna_Stop.mid\n","Importing Pop song called All_Saints_-_I_Know_Where_It's_At.mid\n","Importing Pop song called Brian_McKnight_-_Back_At_One.mid\n","Importing Pop song called Gilbert_O_Sullivan_-_Alone_Again_Naturally.mid\n","Importing Pop song called Chaka_Khan_-_I_Feel_for_You.mid\n","Importing Pop song called The_Carpenters_-_I'll_Never_Fall_in_Love_Again.mid\n","180\n","20\n","[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1]\n"],"name":"stdout"}]},{"metadata":{"id":"xRa6ju5MjxZs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"1a75b453-bb01-4534-9d53-557ebe8a7519","executionInfo":{"status":"ok","timestamp":1552423895302,"user_tz":300,"elapsed":227,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}}},"cell_type":"code","source":["# V_train, V_test, D_train, D_test, T_train, T_test, I_train, I_test, Y_train, Y_test, X_train, X_test, C_train, C_test, train_paths, test_paths\n","V_train[0]"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","        0.        ],\n","       ...,\n","       [0.        , 0.        , 0.78346457, ..., 0.8503937 , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.        , ..., 0.59448819, 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.70472441, ..., 0.        , 0.        ,\n","        0.        ]])"]},"metadata":{"tags":[]},"execution_count":47}]},{"metadata":{"id":"AFni08F9uJhf","colab_type":"code","outputId":"5a88c24b-c71e-4b33-f4d1-59f898915f42","executionInfo":{"status":"ok","timestamp":1552427798008,"user_tz":300,"elapsed":7602,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":2788}},"cell_type":"code","source":["\n","# ----------------------------------------------------------------------------------------------\n","# Build VAE model\n","# ----------------------------------------------------------------------------------------------\n","\n","print('creating model...')\n","\n","model = VAE()\n","model.create( input_dim=input_dim, \n","    output_dim=output_dim, \n","    use_embedding=use_embedding, \n","    embedding_dim=embedding_dim, \n","    input_length=input_length,\n","    output_length=output_length, \n","    latent_rep_size=latent_dim, \n","    vae_loss=vae_loss,\n","    optimizer=optimizer, \n","    activation=activation, \n","    lstm_activation=lstm_activation, \n","    lstm_state_activation=lstm_state_activation,\n","    epsilon_std=epsilon_std, \n","    epsilon_factor=epsilon_factor,\n","    include_composer_decoder=include_composer_decoder,\n","    num_composers=num_composers, \n","    composer_weight=composer_weight, \n","    lstm_size=lstm_size, \n","    cell_type='LSTM',\n","    num_layers_encoder=num_layers_encoder, \n","    num_layers_decoder=num_layers_decoder, \n","    bidirectional=bidirectional, \n","    decode=decode, \n","    teacher_force=teacher_force, \n","    learning_rate=learning_rate, \n","    split_lstm_vector=split_lstm_vector, \n","    history=history, \n","    beta=beta, \n","    prior_mean=prior_mean,\n","    prior_std=prior_std,\n","    decoder_additional_input=decoder_additional_input, \n","    decoder_additional_input_dim=decoder_additional_input_dim, \n","    extra_layer=extra_layer,\n","    meta_instrument= meta_instrument,\n","    meta_instrument_dim= meta_instrument_dim,\n","    meta_instrument_length=meta_instrument_length,\n","    meta_instrument_activation=meta_instrument_activation,\n","    meta_instrument_weight = meta_instrument_weight,\n","    signature_decoder = signature_decoder,\n","    signature_dim = signature_dim,\n","    signature_activation = signature_activation,\n","    signature_weight = signature_weight,\n","    composer_decoder_at_notes_output=composer_decoder_at_notes_output,\n","    composer_decoder_at_notes_weight=composer_decoder_at_notes_weight,\n","    composer_decoder_at_notes_activation=composer_decoder_at_notes_activation,\n","    composer_decoder_at_instrument_output=composer_decoder_at_instrument_output,\n","    composer_decoder_at_instrument_weight=composer_decoder_at_instrument_weight,\n","    composer_decoder_at_instrument_activation=composer_decoder_at_instrument_activation,\n","    meta_velocity=meta_velocity,\n","    meta_velocity_length=meta_velocity_length,\n","    meta_velocity_activation=meta_velocity_activation,\n","    meta_velocity_weight=meta_velocity_weight,\n","    meta_held_notes=meta_held_notes,\n","    meta_held_notes_length=meta_held_notes_length,\n","    meta_held_notes_activation=meta_held_notes_activation,\n","    meta_held_notes_weight=meta_held_notes_weight,\n","    meta_next_notes=meta_next_notes,\n","    meta_next_notes_output_length=meta_next_notes_output_length,\n","    meta_next_notes_weight=meta_next_notes_weight,\n","    meta_next_notes_teacher_force=meta_next_notes_teacher_force,\n","    activation_before_splitting=activation_before_splitting\n","    )\n","\n","encoder = model.encoder\n","decoder = model.decoder\n","autoencoder = model.autoencoder\n","\n","print(encoder.summary())\n","print(decoder.summary())\n","print(autoencoder.summary())\n","\n","\n","if load_previous_checkpoint:\n","    autoencoder.load_weights(previous_checkpoint_path +'autoencoder'+'Epoch'+str(previous_epoch)+'.pickle', by_name=False)\n","    encoder.load_weights(previous_checkpoint_path+'encoder'+'Epoch'+str(previous_epoch)+'.pickle', by_name=False)\n","    decoder.load_weights(previous_checkpoint_path+'decoder'+'Epoch'+str(previous_epoch)+'.pickle', by_name=False)\n","\n","    print(\"Successfully loaded previous epochs\")\n","\n","    if reset_states:\n","        autoencoder.reset_states()\n","        encoder.reset_states()\n","        decoder.reset_states()\n"],"execution_count":52,"outputs":[{"output_type":"stream","text":["creating model...\n","____________________________________________________________________________________________________\n","Layer (type)                     Output Shape          Param #     Connected to                     \n","====================================================================================================\n","notes_input (InputLayer)         (None, 64, 61)        0                                            \n","____________________________________________________________________________________________________\n","lstm_1 (LSTM)                    (None, 64, 256)       325632      notes_input[0][0]                \n","____________________________________________________________________________________________________\n","meta_instrument_input (InputLaye (None, 4, 16)         0                                            \n","____________________________________________________________________________________________________\n","lstm_2 (LSTM)                    (None, 256)           525312      lstm_1[0][0]                     \n","____________________________________________________________________________________________________\n","lstm_meta_instrument (LSTM)      (None, 256)           279552      meta_instrument_input[0][0]      \n","____________________________________________________________________________________________________\n","meta_velocity_input (InputLayer) (None, 64, 1)         0                                            \n","____________________________________________________________________________________________________\n","concatenated_instrument_and_note (None, 512)           0           lstm_2[0][0]                     \n","                                                                   lstm_meta_instrument[0][0]       \n","____________________________________________________________________________________________________\n","lstm_meta_velocity (LSTM)        (None, 256)           264192      meta_velocity_input[0][0]        \n","____________________________________________________________________________________________________\n","concatenated_velocity_and_rest_l (None, 768)           0           concatenated_instrument_and_notes\n","                                                                   lstm_meta_velocity[0][0]         \n","____________________________________________________________________________________________________\n","extra_instrument_after_concat_la (None, 256)           196864      concatenated_velocity_and_rest_la\n","____________________________________________________________________________________________________\n","extra_layer (Dense)              (None, 256)           65792       extra_instrument_after_concat_lay\n","____________________________________________________________________________________________________\n","lambda_28 (Lambda)               (None, 128)           0           extra_layer[0][0]                \n","____________________________________________________________________________________________________\n","lambda_29 (Lambda)               (None, 128)           0           extra_layer[0][0]                \n","____________________________________________________________________________________________________\n","z_mean (Dense)                   (None, 256)           33024       lambda_28[0][0]                  \n","____________________________________________________________________________________________________\n","z_log_var (Dense)                (None, 256)           33024       lambda_29[0][0]                  \n","____________________________________________________________________________________________________\n","kl_layer (KLDivergenceLayer)     [(None, 256), (None,  0           z_mean[0][0]                     \n","                                                                   z_log_var[0][0]                  \n","____________________________________________________________________________________________________\n","lambda (Lambda)                  (None, 256)           0           kl_layer[0][0]                   \n","                                                                   kl_layer[0][1]                   \n","====================================================================================================\n","Total params: 1,723,392\n","Trainable params: 1,723,392\n","Non-trainable params: 0\n","____________________________________________________________________________________________________\n","None\n","____________________________________________________________________________________________________\n","Layer (type)                     Output Shape          Param #     Connected to                     \n","====================================================================================================\n","encoded_input (InputLayer)       (None, 256)           0                                            \n","____________________________________________________________________________________________________\n","history_input (InputLayer)       (None, 256)           0                                            \n","____________________________________________________________________________________________________\n","concatenate_2 (Concatenate)      (None, 512)           0           encoded_input[0][0]              \n","                                                                   history_input[0][0]              \n","____________________________________________________________________________________________________\n","input_decoder_start (InputLayer) (None, 61)            0                                            \n","____________________________________________________________________________________________________\n","dense_25 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","dense_26 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","dense_27 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","dense_28 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","input_decoder_meta_instrument_st (None, 16)            0                                            \n","____________________________________________________________________________________________________\n","dense_32 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","dense_33 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","input_decoder_meta_velocity_star (None, 1)             0                                            \n","____________________________________________________________________________________________________\n","dense_37 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","dense_38 (Dense)                 (None, 256)           131328      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","notes (RecurrentModel)           (None, 64, 61)        866621      input_decoder_start[0][0]        \n","                                                                   dense_25[0][0]                   \n","                                                                   dense_26[0][0]                   \n","                                                                   dense_27[0][0]                   \n","                                                                   dense_28[0][0]                   \n","                                                                   input_decoder_start[0][0]        \n","____________________________________________________________________________________________________\n","meta_instrument (RecurrentModel) (None, 4, 16)         283664      input_decoder_meta_instrument_sta\n","                                                                   dense_32[0][0]                   \n","                                                                   dense_33[0][0]                   \n","                                                                   input_decoder_meta_instrument_sta\n","____________________________________________________________________________________________________\n","meta_velocity (RecurrentModel)   (None, 64, 1)         264449      input_decoder_meta_velocity_start\n","                                                                   dense_37[0][0]                   \n","                                                                   dense_38[0][0]                   \n","                                                                   input_decoder_meta_velocity_start\n","====================================================================================================\n","Total params: 2,465,358\n","Trainable params: 2,465,358\n","Non-trainable params: 0\n","____________________________________________________________________________________________________\n","None\n","____________________________________________________________________________________________________\n","Layer (type)                     Output Shape          Param #     Connected to                     \n","====================================================================================================\n","notes_input (InputLayer)         (None, 64, 61)        0                                            \n","____________________________________________________________________________________________________\n","lstm_1 (LSTM)                    (None, 64, 256)       325632      notes_input[0][0]                \n","____________________________________________________________________________________________________\n","meta_instrument_input (InputLaye (None, 4, 16)         0                                            \n","____________________________________________________________________________________________________\n","lstm_2 (LSTM)                    (None, 256)           525312      lstm_1[0][0]                     \n","____________________________________________________________________________________________________\n","lstm_meta_instrument (LSTM)      (None, 256)           279552      meta_instrument_input[0][0]      \n","____________________________________________________________________________________________________\n","meta_velocity_input (InputLayer) (None, 64, 1)         0                                            \n","____________________________________________________________________________________________________\n","concatenated_instrument_and_note (None, 512)           0           lstm_2[0][0]                     \n","                                                                   lstm_meta_instrument[0][0]       \n","____________________________________________________________________________________________________\n","lstm_meta_velocity (LSTM)        (None, 256)           264192      meta_velocity_input[0][0]        \n","____________________________________________________________________________________________________\n","concatenated_velocity_and_rest_l (None, 768)           0           concatenated_instrument_and_notes\n","                                                                   lstm_meta_velocity[0][0]         \n","____________________________________________________________________________________________________\n","extra_instrument_after_concat_la (None, 256)           196864      concatenated_velocity_and_rest_la\n","____________________________________________________________________________________________________\n","extra_layer (Dense)              (None, 256)           65792       extra_instrument_after_concat_lay\n","____________________________________________________________________________________________________\n","lambda_28 (Lambda)               (None, 128)           0           extra_layer[0][0]                \n","____________________________________________________________________________________________________\n","lambda_29 (Lambda)               (None, 128)           0           extra_layer[0][0]                \n","____________________________________________________________________________________________________\n","z_mean (Dense)                   (None, 256)           33024       lambda_28[0][0]                  \n","____________________________________________________________________________________________________\n","z_log_var (Dense)                (None, 256)           33024       lambda_29[0][0]                  \n","____________________________________________________________________________________________________\n","kl_layer (KLDivergenceLayer)     [(None, 256), (None,  0           z_mean[0][0]                     \n","                                                                   z_log_var[0][0]                  \n","____________________________________________________________________________________________________\n","input_decoder_start (InputLayer) (None, 61)            0                                            \n","____________________________________________________________________________________________________\n","lambda (Lambda)                  (None, 256)           0           kl_layer[0][0]                   \n","                                                                   kl_layer[0][1]                   \n","____________________________________________________________________________________________________\n","history_input (InputLayer)       (None, 256)           0                                            \n","____________________________________________________________________________________________________\n","input_decoder_meta_instrument_st (None, 16)            0                                            \n","____________________________________________________________________________________________________\n","input_decoder_meta_velocity_star (None, 1)             0                                            \n","____________________________________________________________________________________________________\n","decoder (Model)                  [(None, 64, 61), (Non 2465358     input_decoder_start[0][0]        \n","                                                                   lambda[0][0]                     \n","                                                                   history_input[0][0]              \n","                                                                   input_decoder_meta_instrument_sta\n","                                                                   input_decoder_meta_velocity_start\n","____________________________________________________________________________________________________\n","composer_decoder (Model)         (None, 2)             0           lambda[0][0]                     \n","====================================================================================================\n","Total params: 4,188,750\n","Trainable params: 4,188,750\n","Non-trainable params: 0\n","____________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"tNsHlnLTuMX_","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# ----------------------------------------------------------------------------------------------\n","# Prepare model path\n","# ----------------------------------------------------------------------------------------------\n","\n","t = str(time.time())\n","fd = {'include_composer_feature': include_composer_feature, 'highcrop': high_crop, 'lowcrop':low_crop, 'lr': learning_rate, 'opt': optimizer,\n","'bi': bidirectional, 'lstm_size': lstm_size, 'latent': latent_dim, 'trainsize': train_set_size, 'testsize': test_set_size, 'input_length': input_length,\n","'output_length': output_length, 'reset_states': reset_states, 'compdec': include_composer_decoder, 'num_layers_encoder': num_layers_encoder, 'num_layers_decoder': num_layers_decoder, \n","'beta': beta, 'lr': learning_rate, 'epsstd': epsilon_std}\n","model_name = t+'-_ls_inlen_%(input_length)s_outlen_%(output_length)s_beta_%(beta)s_lr_%(lr)s_lstmsize_%(lstm_size)s_latent_%(latent)s_trainsize_%(trainsize)s_testsize_%(testsize)s_epsstd_%(epsstd)s' % fd\n","\n","model_path = model_path + model_name + '/'\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9h5EXmAnuhGS","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# ----------------------------------------------------------------------------------------------\n","# Test function\n","# ----------------------------------------------------------------------------------------------\n","\n","enumerated_metric_names = []\n","metric_names_total_dict = dict()\n","metric_names_count_dict = dict()\n","for name in autoencoder.metrics_names:\n","    if name in metric_names_count_dict.keys():\n","        metric_names_total_dict[name] += 1\n","    else:\n","        metric_names_total_dict[name] = 1\n","        #initialize count dict\n","        metric_names_count_dict[name] = 0\n","for name in autoencoder.metrics_names:\n","    if metric_names_total_dict[name] > 1:\n","        metric_names_count_dict[name] += 1\n","        enumerated_metric_names.append(name + \"_\" + str(metric_names_count_dict[name]))\n","    else:\n","        enumerated_metric_names.append(name)\n","\n","# initialize loss arrays\n","total_test_notes_loss_array = []\n","total_train_notes_loss_array = []\n","total_test_loss_array = [] \n","total_train_loss_array = []\n","total_train_accuracy_array = []\n","total_test_accuracy_array = []\n","max_test_accuracy = 0\n","\n","total_train_meta_instrument_accuracy_array = []\n","total_test_meta_instrument_accuracy_array = []\n","total_train_meta_instrument_loss_array = []\n","total_test_meta_instrument_loss_array = []\n","\n","total_train_meta_velocity_accuracy_array = []\n","total_test_meta_velocity_accuracy_array = []\n","total_train_meta_velocity_loss_array = []\n","total_test_meta_velocity_loss_array = []\n","\n","total_train_meta_held_notes_accuracy_array = []\n","total_test_meta_held_notes_accuracy_array = []\n","total_train_meta_held_notes_loss_array = []\n","total_test_meta_held_notes_loss_array = []\n","\n","total_train_meta_next_notes_accuracy_array = []\n","total_test_meta_next_notes_accuracy_array = []\n","total_train_meta_next_notes_loss_array = []\n","total_test_meta_next_notes_loss_array = []\n","\n","total_train_composer_accuracy_array = []\n","total_train_composer_loss_array = []\n","total_test_composer_accuracy_array = []\n","total_test_composer_loss_array = []\n","\n","total_train_signature_accuracy_array = []\n","total_train_signature_loss_array = []\n","total_test_signature_accuracy_array = []\n","total_test_signature_loss_array = []\n","\n","total_test_kl_loss_array = []\n","total_train_kl_loss_array = []\n","\n","total_train_composer_instrument_accuracy_array = []\n","total_train_composer_instrument_loss_array = []\n","total_test_composer_instrument_accuracy_array = []\n","total_test_composer_instrument_loss_array = []\n","\n","total_train_composer_notes_accuracy_array = []\n","total_train_composer_notes_loss_array = []\n","total_test_composer_notes_accuracy_array = []\n","total_test_composer_notes_loss_array = []\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b6dHU4pYNdVy","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Test function\n","def test():\n","    global max_test_accuracy\n","    print('\\nTesting:')\n","    total_test_loss = 0\n","    total_test_accuracy = 0\n","    total_test_notes_loss = 0\n","\n","    total_test_meta_instrument_loss = 0\n","    total_test_meta_instrument_accuracy = 0\n","    total_test_meta_velocity_loss = 0\n","    total_test_meta_velocity_accuracy = 0\n","    total_test_meta_held_notes_loss = 0\n","    total_test_meta_held_notes_accuracy = 0\n","\n","    total_test_meta_next_notes_loss = 0\n","    total_test_meta_next_notes_accuracy = 0\n","\n","\n","    total_test_loss_composer = 0\n","    total_test_accuracy_composer = 0\n","\n","    total_test_loss_signature = 0\n","    total_test_signature_accuracy = 0\n","\n","    total_test_loss_composer_notes = 0\n","    total_test_composer_notes_accuracy = 0\n","    total_test_loss_composer_instrument = 0\n","    total_test_composer_instrument_accuracy = 0\n","    \n","    bar = progressbar.ProgressBar(max_value=test_set_size, redirect_stdout=False)\n","    for test_song_num in range(len(X_test)):\n","\n","        X = X_test[test_song_num]\n","        Y = Y_test[test_song_num]\n","        C = C_test[test_song_num]\n","        I = I_test[test_song_num]\n","        V = V_test[test_song_num]\n","        D = D_test[test_song_num]\n","        S = normalized_S_test[test_song_num]\n","\n","        T = T_test[test_song_num] #not yet used\n","\n","        #calculate history if desired\n","        if history:\n","            #get the representation by feeding the inputs into the encoder\n","            encoder_input_list = vae_definition.prepare_encoder_input_list(X,I,V,D)\n","            representation_list = encoder.predict(encoder_input_list, batch_size=batch_size, verbose=False)\n","            #roll the list by one to save the representation of the last sample for each input\n","            H = np.zeros(representation_list.shape)\n","            H[1:] = representation_list[:-1]\n","\n","        else:\n","            H = np.zeros((X.shape[0], latent_dim))\n","\n","\n","        input_list, output_list = vae_definition.prepare_autoencoder_input_and_output_list(X,Y,C,I,V,D,S,H, return_sample_weight=False)\n","        \n","        loss = autoencoder.evaluate(input_list, output_list, batch_size=batch_size, verbose=False)\n","\n","        total_test_loss += loss[0]\n","        if meta_instrument or meta_velocity or meta_held_notes or meta_next_notes:\n","\n","            count = 1\n","            total_test_notes_loss += loss[enumerated_metric_names.index('decoder_loss_' + str(count))]\n","            total_test_accuracy += loss[enumerated_metric_names.index('decoder_acc_1')]\n","            \n","            if meta_instrument:\n","                count +=1\n","                total_test_meta_instrument_loss += loss[enumerated_metric_names.index('decoder_loss_' + str(count))]\n","                total_test_meta_instrument_accuracy += loss[enumerated_metric_names.index('decoder_acc_' + str(count))]\n","\n","            if meta_velocity:\n","                count += 1\n","                total_test_meta_velocity_loss += loss[enumerated_metric_names.index('decoder_loss_' + str(count))]\n","                total_test_meta_velocity_accuracy += loss[enumerated_metric_names.index('decoder_acc_' + str(count))]\n","\n","            if meta_held_notes:\n","                count += 1\n","                total_test_meta_held_notes_loss += loss[enumerated_metric_names.index('decoder_loss_' + str(count))]\n","                total_test_meta_held_notes_accuracy += loss[enumerated_metric_names.index('decoder_acc_' + str(count))]\n","\n","            if meta_next_notes:\n","                count += 1\n","                total_test_meta_next_notes_loss += loss[enumerated_metric_names.index('decoder_loss_' + str(count))]\n","                total_test_meta_next_notes_accuracy += loss[enumerated_metric_names.index('decoder_acc_' + str(count))]\n","\n","        else:\n","            if len(enumerated_metric_names) > 2:\n","                total_test_accuracy += loss[enumerated_metric_names.index('decoder_acc')]\n","                total_test_notes_loss += loss[enumerated_metric_names.index('decoder_loss')]\n","            else:\n","                total_test_notes_loss += loss[0]\n","                total_test_accuracy += loss[1]\n","\n","        if include_composer_decoder:\n","            total_test_loss_composer += loss[enumerated_metric_names.index('composer_decoder_loss')]\n","            total_test_accuracy_composer += loss[enumerated_metric_names.index('composer_decoder_acc')]\n","\n","        if signature_decoder:\n","            total_test_loss_signature += loss[enumerated_metric_names.index('signature_decoder_loss')]\n","            total_test_signature_accuracy += loss[enumerated_metric_names.index('signature_decoder_acc')]\n","\n","        if composer_decoder_at_notes_output:\n","            total_test_loss_composer_notes += loss[enumerated_metric_names.index('composer_decoder_at_notes_loss')]\n","            total_test_composer_notes_accuracy += loss[enumerated_metric_names.index('composer_decoder_at_notes_acc')]\n","\n","        if composer_decoder_at_instrument_output:\n","            total_test_loss_composer_instrument += loss[enumerated_metric_names.index('composer_decoder_at_instruments_loss')]\n","            total_test_composer_instrument_accuracy += loss[enumerated_metric_names.index('composer_decoder_at_instruments_acc')]\n","        \n","        if reset_states:\n","            autoencoder.reset_states()\n","        \n","              \n","        bar.update(test_song_num+1)\n","\n","    plt.close('all')\n","    f, axarr = plt.subplots(3,2, sharex=True, figsize=(15.0, 20.0))\n","    f.suptitle(t)\n","    \n","    \n","    if include_composer_decoder:\n","        composer_accuracy = total_test_accuracy_composer/test_set_size\n","        composer_loss = total_test_loss_composer/test_set_size\n","        total_test_composer_loss_array.append(composer_loss)\n","        total_test_composer_accuracy_array.append(composer_accuracy)\n","        print('\\nTest composer accuracy: ', composer_accuracy)\n","        print('Test composer loss: ', composer_loss)\n","        axarr[1,1].plot(total_test_composer_accuracy_array,  label='Test composer accuracy')\n","        axarr[1,0].plot(total_train_composer_accuracy_array,  label='Train composer accuracy')\n","        axarr[0,1].plot(total_test_composer_loss_array,  label='Test composer loss')\n","        axarr[0,0].plot(total_train_composer_loss_array,  label='Train composer loss')\n","        pickle.dump(total_test_composer_loss_array,open(model_path+'total_test_composer_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_composer_loss_array,open(model_path+'total_train_composer_loss_array.pickle', 'wb'))\n","        pickle.dump(total_test_composer_accuracy_array,open(model_path+'total_test_composer_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_composer_accuracy_array,open(model_path+'total_train_composer_accuracy_array.pickle', 'wb'))\n","\n","    if meta_instrument:\n","        meta_instrument_accuracy = total_test_meta_instrument_accuracy/test_set_size\n","        meta_instrument_loss = total_test_meta_instrument_loss/test_set_size\n","        total_test_meta_instrument_loss_array.append(meta_instrument_loss)\n","        total_test_meta_instrument_accuracy_array.append(meta_instrument_accuracy)\n","        print('Test meta instrument accuracy: ', meta_instrument_accuracy)\n","        print('Test meta instrument loss: ', meta_instrument_loss)\n","        axarr[1,1].plot(total_test_meta_instrument_accuracy_array, label='Test instrument accuracy')\n","        axarr[1,0].plot(total_train_meta_instrument_accuracy_array, label='Train instrument accuracy')\n","        axarr[0,1].plot(total_test_meta_instrument_loss_array, label='Test instrument loss')\n","        axarr[0,0].plot(total_train_meta_instrument_loss_array, label='Train instrument loss')\n","        pickle.dump(total_test_meta_instrument_loss_array,open(model_path+'total_test_meta_instrument_loss_array.pickle', 'wb'))\n","        pickle.dump(total_test_meta_instrument_accuracy_array,open(model_path+'total_test_meta_instrument_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_instrument_loss_array,open(model_path+'total_train_meta_instrument_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_instrument_accuracy_array,open(model_path+'total_train_meta_instrument_accuracy_array.pickle', 'wb'))\n","\n","    if meta_held_notes:\n","        meta_held_notes_accuracy = total_test_meta_held_notes_accuracy/test_set_size\n","        meta_held_notes_loss = total_test_meta_held_notes_loss/test_set_size\n","        total_test_meta_held_notes_loss_array.append(meta_held_notes_loss)\n","        total_test_meta_held_notes_accuracy_array.append(meta_held_notes_accuracy)\n","        print('Test meta held_notes accuracy: ', meta_held_notes_accuracy)\n","        print('Test meta held_notes loss: ', meta_held_notes_loss)\n","        axarr[1,1].plot(total_test_meta_held_notes_accuracy_array, label='Test held_notes accuracy')\n","        axarr[1,0].plot(total_train_meta_held_notes_accuracy_array, label='Train held_notes accuracy')\n","        axarr[0,1].plot(total_test_meta_held_notes_loss_array, label='Test held_notes loss')\n","        axarr[0,0].plot(total_train_meta_held_notes_loss_array, label='Train held_notes loss')\n","        pickle.dump(total_test_meta_held_notes_loss_array,open(model_path+'total_test_meta_held_notes_loss_array.pickle', 'wb'))\n","        pickle.dump(total_test_meta_held_notes_accuracy_array,open(model_path+'total_test_meta_held_notes_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_held_notes_loss_array,open(model_path+'total_train_meta_held_notes_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_held_notes_accuracy_array,open(model_path+'total_train_meta_held_notes_accuracy_array.pickle', 'wb'))\n","\n","    if meta_next_notes:\n","        meta_next_notes_accuracy = total_test_meta_next_notes_accuracy/test_set_size\n","        meta_next_notes_loss = total_test_meta_next_notes_loss/test_set_size\n","        total_test_meta_next_notes_loss_array.append(meta_next_notes_loss)\n","        total_test_meta_next_notes_accuracy_array.append(meta_next_notes_accuracy)\n","        print('Test meta next_notes accuracy: ', meta_next_notes_accuracy)\n","        print('Test meta next_notes loss: ', meta_next_notes_loss)\n","        axarr[1,1].plot(total_test_meta_next_notes_accuracy_array, label='Test next_notes accuracy')\n","        axarr[1,0].plot(total_train_meta_next_notes_accuracy_array, label='Train next_notes accuracy')\n","        axarr[0,1].plot(total_test_meta_next_notes_loss_array, label='Test next_notes loss')\n","        axarr[0,0].plot(total_train_meta_next_notes_loss_array, label='Train next_notes loss')\n","        pickle.dump(total_test_meta_next_notes_loss_array,open(model_path+'total_test_meta_next_notes_loss_array.pickle', 'wb'))\n","        pickle.dump(total_test_meta_next_notes_accuracy_array,open(model_path+'total_test_meta_next_notes_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_next_notes_loss_array,open(model_path+'total_train_meta_next_notes_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_next_notes_accuracy_array,open(model_path+'total_train_meta_next_notes_accuracy_array.pickle', 'wb'))\n","\n","    if composer_decoder_at_notes_output:\n","        composer_notes_accuracy = total_test_composer_notes_accuracy/test_set_size\n","        composer_notes_loss = total_test_loss_composer_notes/test_set_size\n","        total_test_composer_notes_loss_array.append(composer_notes_loss)\n","        total_test_composer_notes_accuracy_array.append(composer_notes_accuracy)\n","        print('Test composer_notes accuracy: ', composer_notes_accuracy)\n","        print('Test composer_notes loss: ', composer_notes_loss)\n","        axarr[1,1].plot(total_test_composer_notes_accuracy_array, label='Test composer_notes accuracy')\n","        axarr[1,0].plot(total_train_composer_notes_accuracy_array, label='Train composer_notes accuracy')\n","        axarr[0,1].plot(total_test_composer_notes_loss_array, label='Test composer_notes loss')\n","        axarr[0,0].plot(total_train_composer_notes_loss_array, label='Train composer_notes loss')\n","        pickle.dump(total_test_composer_notes_loss_array,open(model_path+'total_test_composer_notes_loss_array.pickle', 'wb'))\n","        pickle.dump(total_test_composer_notes_accuracy_array,open(model_path+'total_test_composer_notes_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_composer_notes_loss_array,open(model_path+'total_train_composer_notes_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_composer_notes_accuracy_array,open(model_path+'total_train_composer_notes_accuracy_array.pickle', 'wb'))\n","\n","    if composer_decoder_at_instrument_output:\n","        composer_instrument_accuracy = total_test_composer_instrument_accuracy/test_set_size\n","        composer_instrument_loss = total_test_loss_composer_instrument/test_set_size\n","        total_test_composer_instrument_loss_array.append(composer_instrument_loss)\n","        total_test_composer_instrument_accuracy_array.append(composer_instrument_accuracy)\n","        print('Test composer_instrument accuracy: ', composer_instrument_accuracy)\n","        print('Test composer_instrument loss: ', composer_instrument_loss)\n","        axarr[1,1].plot(total_test_composer_instrument_accuracy_array, label='Test composer_instrument accuracy')\n","        axarr[1,0].plot(total_train_composer_instrument_accuracy_array, label='Train composer_instrument accuracy')\n","        axarr[0,1].plot(total_test_composer_instrument_loss_array, label='Test composer_instrument loss')\n","        axarr[0,0].plot(total_train_composer_instrument_loss_array, label='Train composer_instrument loss')\n","        pickle.dump(total_test_composer_instrument_loss_array,open(model_path+'total_test_composer_instrument_loss_array.pickle', 'wb'))\n","        pickle.dump(total_test_composer_instrument_accuracy_array,open(model_path+'total_test_composer_instrument_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_composer_instrument_loss_array,open(model_path+'total_train_composer_instrument_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_composer_instrument_accuracy_array,open(model_path+'total_train_composer_instrument_accuracy_array.pickle', 'wb'))\n","\n","    accuracy = total_test_accuracy/test_set_size\n","    if max_test_accuracy < accuracy:\n","        max_test_accuracy = accuracy\n","    total_test_accuracy_array.append(accuracy)\n","    notes_loss = total_test_notes_loss / test_set_size\n","    total_test_notes_loss_array.append(notes_loss)\n","    print('Test notes accuracy: ', accuracy)\n","    print('Test notes loss: ', notes_loss)\n","    axarr[1,1].plot(total_test_accuracy_array, label='Test notes accuracy')\n","    axarr[1,0].plot(total_train_accuracy_array, label='Train notes accuracy')\n","    axarr[0,1].plot(total_test_notes_loss_array, label='Test notes loss')\n","    axarr[0,0].plot(total_train_notes_loss_array, label='Train notes loss')\n","    pickle.dump(total_train_accuracy_array,open(model_path+'total_train_accuracy_array.pickle', 'wb'))\n","    pickle.dump(total_test_accuracy_array,open(model_path+'total_test_accuracy_array.pickle', 'wb'))\n","    pickle.dump(total_test_notes_loss_array,open(model_path+'total_test_notes_loss_array.pickle', 'wb'))\n","    pickle.dump(total_train_notes_loss_array,open(model_path+'total_train_notes_loss_array.pickle', 'wb'))\n","\n","    if meta_velocity:\n","        meta_velocity_accuracy = total_test_meta_velocity_accuracy/test_set_size\n","        meta_velocity_loss = total_test_meta_velocity_loss/test_set_size\n","        total_test_meta_velocity_loss_array.append(meta_velocity_loss)\n","        total_test_meta_velocity_accuracy_array.append(meta_velocity_accuracy)\n","        #Accuracy is logged for meta_velocity (it outputs accuracy metric for all losses) but it does not make sense, so don't show it or save it\n","        #only plot and save it if it is combined with the held notes (which have accuracy)\n","        if combine_velocity_and_held_notes or velocity_threshold_such_that_it_is_a_played_note >= 0.5:\n","            print('Test meta velocity accuracy: ', meta_velocity_accuracy)\n","        print('Test meta velocity loss: ', meta_velocity_loss)\n","        if combine_velocity_and_held_notes:\n","            axarr[1,1].plot(total_test_meta_velocity_accuracy_array, label='Test velocity accuracy')\n","            axarr[1,0].plot(total_train_meta_velocity_accuracy_array, label='Train velocity accuracy')\n","        axarr[0,1].plot(total_test_meta_velocity_loss_array, label='Test velocity loss')\n","        axarr[0,0].plot(total_train_meta_velocity_loss_array, label='Train velocity loss')\n","        pickle.dump(total_test_meta_velocity_loss_array,open(model_path+'total_test_meta_velocity_loss_array.pickle', 'wb'))\n","        if combine_velocity_and_held_notes or velocity_threshold_such_that_it_is_a_played_note >= 0.5:\n","            pickle.dump(total_test_meta_velocity_accuracy_array,open(model_path+'total_test_meta_velocity_accuracy_array.pickle', 'wb'))\n","            pickle.dump(total_train_meta_velocity_accuracy_array,open(model_path+'total_train_meta_velocity_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_meta_velocity_loss_array,open(model_path+'total_train_meta_velocity_loss_array.pickle', 'wb'))\n","\n","    \n","\n","    if signature_decoder:\n","        signature_accuracy = total_test_signature_accuracy/test_set_size\n","        signature_loss = total_test_loss_signature/test_set_size\n","        total_test_signature_loss_array.append(signature_loss)\n","        total_test_signature_accuracy_array.append(signature_accuracy)\n","        #Don't plot signature accuracy since it makes no sense in regression problem\n","        #print('Test signature accuracy: ', signature_accuracy)\n","        print('Test signature loss: ', signature_loss)\n","        #axarr[1,1].plot(total_test_signature_accuracy_array, label='Test signature accuracy')\n","        #axarr[1,0].plot(total_train_signature_accuracy_array, label='Train signature accuracy')\n","        axarr[0,1].plot(total_test_signature_loss_array, label='Test signature loss')\n","        axarr[0,0].plot(total_train_signature_loss_array, label='Train signature loss')\n","        pickle.dump(total_test_signature_loss_array,open(model_path+'total_test_signature_loss_array.pickle', 'wb'))\n","        #pickle.dump(total_test_signature_accuracy_array,open(model_path+'total_test_signature_accuracy_array.pickle', 'wb'))\n","        pickle.dump(total_train_signature_loss_array,open(model_path+'total_train_signature_loss_array.pickle', 'wb'))\n","        #pickle.dump(total_train_signature_accuracy_array,open(model_path+'total_train_signature_accuracy_array.pickle', 'wb'))\n","    \n","\n","    \n","\n","    test_loss = total_test_loss/test_set_size\n","    total_test_loss_array.append(test_loss)\n","\n","    \n","\n","    if beta > 0:\n","        #TODO. adjust by weights?\n","        kl_loss = test_loss - notes_loss * 1.0\n","        if include_composer_decoder: kl_loss -= composer_loss * composer_weight\n","        if meta_instrument: kl_loss -= meta_instrument_loss * meta_instrument_weight\n","        if meta_velocity: kl_loss -= meta_velocity_loss * meta_velocity_weight\n","        if meta_held_notes: kl_loss -= meta_held_notes_loss * meta_held_notes_weight\n","        if meta_next_notes: kl_loss -= meta_next_notes_loss * meta_next_notes_weight\n","        if signature_decoder: kl_loss -= signature_loss * signature_weight\n","        if composer_decoder_at_notes_output: kl_loss -= composer_notes_loss * composer_decoder_at_notes_weight\n","        if composer_decoder_at_instrument_output: kl_loss -= composer_instrument_loss * composer_decoder_at_instrument_weight\n","        #since you get the value back weighted, scale back by dividing by beta\n","        kl_loss = kl_loss / beta\n","        total_test_kl_loss_array.append(kl_loss)\n","        axarr[2,1].plot(total_test_kl_loss_array, label='Test KL loss')\n","        axarr[2,0].plot(total_train_kl_loss_array, label='Train KL loss')\n","        print('Test KL loss: ', kl_loss)\n","        pickle.dump(total_test_kl_loss_array,open(model_path+'total_test_kl_loss_array.pickle', 'wb'))\n","        pickle.dump(total_train_kl_loss_array,open(model_path+'total_train_kl_loss_array.pickle', 'wb'))\n","\n","    print('Total test loss: ', test_loss)\n","\n","\n","    axarr[0,1].plot(total_test_loss_array, label='Total test loss')\n","    axarr[0,0].plot(total_train_loss_array, label='Total train loss')\n","    pickle.dump(total_test_loss_array,open(model_path+'total_test_loss_array.pickle', 'wb'))\n","    pickle.dump(total_train_loss_array,open(model_path+'total_train_loss_array.pickle', 'wb'))\n","\n","    axarr[2,1].set_title(\"Test KL loss\",fontsize=10)\n","    axarr[2,0].set_title(\"Train KL loss\", fontsize=10)\n","    axarr[1,1].set_title(\"Test accuracies - Max notes acc: %4.2f\" % max_test_accuracy, fontsize=10)\n","    axarr[1,0].set_title(\"Train accuracies\", fontsize=10)\n","    axarr[0,1].set_title(\"Test losses\",fontsize=10)\n","    axarr[0,0].set_title(\"Train losses\", fontsize=10)\n","    axarr[2,1].legend(loc='upper right', prop={'size': 8})\n","    axarr[2,0].legend(loc='upper right', prop={'size': 8})\n","    axarr[1,1].legend(loc='lower right', prop={'size': 8})\n","    axarr[1,0].legend(loc='lower right', prop={'size': 8})\n","    axarr[0,1].legend(loc='upper right', prop={'size': 8})\n","    axarr[0,0].legend(loc='upper right', prop={'size': 8})\n","\n","    if show_plot: f.show()\n","    if save_plot: f.savefig(model_path+'plot.png')\n","    print('-'*50)\n","    \n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"AAO-QsWyNvnE","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# ----------------------------------------------------------------------------------------------\n","# Save parameters file\n","# ----------------------------------------------------------------------------------------------\n","\n","# Save Parameters to text file\n","with open(model_path + 'params.txt', \"w\", encoding='utf-8') as text_file:\n","    text_file.write(\"load_from_pickle_instead_of_midi: %s\" % load_from_pickle_instead_of_midi + '\\n')\n","    text_file.write(\"pickle_load_path: %s\" % pickle_load_path + '\\n')\n","    text_file.write(\"epochs: %s\" % epochs + '\\n')\n","    text_file.write(\"input_dim: %s\" % input_dim + '\\n')\n","    text_file.write(\"output_dim: %s\" % output_dim + '\\n')\n","    text_file.write(\"attach_instruments: %s\" % attach_instruments + '\\n')\n","    text_file.write(\"instrument_dim: %s\" % instrument_dim + '\\n')\n","    text_file.write(\"include_only_monophonic_instruments: %s\" % include_only_monophonic_instruments + '\\n')\n","    text_file.write(\"instrument_attach_method: %s\" % instrument_attach_method + '\\n')\n","    text_file.write(\"equal_mini_songs: %s\" % equal_mini_songs + '\\n')\n","    text_file.write(\"train_set_size: %s\" % train_set_size + '\\n')\n","    text_file.write(\"test_set_size: %s\" % test_set_size + '\\n')\n","    text_file.write(\"batch_size: %s\" % batch_size + '\\n')\n","    text_file.write(\"learning_rate: %s\" % learning_rate + '\\n')\n","    text_file.write(\"beta: %s\" % beta + '\\n')\n","    text_file.write(\"prior_mean: %s\" % prior_mean + '\\n')\n","    text_file.write(\"prior_std: %s\" % prior_std + '\\n')\n","    text_file.write(\"save_step: %s\" % save_step + '\\n')\n","    text_file.write(\"shuffle_train_set: %s\" % shuffle_train_set + '\\n')\n","    text_file.write(\"test_step: %s\" % test_step + '\\n')\n","    text_file.write(\"bidirectional: %s\" % bidirectional + '\\n')\n","    text_file.write(\"teacher_force: %s\" % teacher_force + '\\n')\n","    text_file.write(\"include_composer_decoder: %s\" % include_composer_decoder + '\\n')\n","    text_file.write(\"composer_weight: %s\" % composer_weight + '\\n')\n","    text_file.write(\"include_composer_feature: %s\" % include_composer_feature + '\\n')\n","    text_file.write(\"max_voices: %s\" % max_voices + '\\n')\n","    text_file.write(\"num_layers_encoder: %s\" % num_layers_encoder + '\\n')\n","    text_file.write(\"num_layers_decoder: %s\" % num_layers_decoder + '\\n')\n","    text_file.write(\"optimizer: %s\" % optimizer + '\\n')\n","    text_file.write(\"cell_type: %s\" % cell_type + '\\n')\n","    text_file.write(\"lstm_size: %s\" % lstm_size + '\\n')\n","    text_file.write(\"latent_dim: %s\" % latent_dim + '\\n')\n","    text_file.write(\"split_lstm_vector: %s\" % split_lstm_vector + '\\n')\n","    text_file.write(\"extra_layer: %s\" % extra_layer + '\\n')\n","    text_file.write(\"history: %s\" % history + '\\n')\n","    text_file.write(\"include_silent_note: %s\" % include_silent_note + '\\n')\n","    text_file.write(\"silent_weight: %s\" % silent_weight + '\\n')\n","    text_file.write(\"activation: %s\" % activation + '\\n')\n","    text_file.write(\"lstm_activation: %s\" % lstm_activation + '\\n')\n","    text_file.write(\"lstm_state_activation: %s\" % lstm_state_activation + '\\n')\n","    text_file.write(\"decoder_additional_input: %s\" % decoder_additional_input + '\\n')\n","    text_file.write(\"decoder_additional_input_dim: %s\" % decoder_additional_input_dim + '\\n')\n","    text_file.write(\"decoder_input_composer: %s\" % decoder_input_composer + '\\n')\n","    text_file.write(\"epsilon_std: %s\" % epsilon_std + '\\n')\n","    text_file.write(\"epsilon_factor: %s\" % epsilon_factor + '\\n')\n","    text_file.write(\"append_signature_vector_to_latent: %s\" % append_signature_vector_to_latent + '\\n')\n","    text_file.write(\"song_completion: %s\" % song_completion + '\\n')\n","    text_file.write(\"meta_instrument: %s\" % meta_instrument + '\\n')\n","    text_file.write(\"meta_instrument_dim: %s\" % meta_instrument_dim + '\\n')\n","    text_file.write(\"meta_instrument_length: %s\" % meta_instrument_length + '\\n')\n","    text_file.write(\"meta_instrument_activation: %s\" % meta_instrument_activation + '\\n')\n","    text_file.write(\"meta_instrument_weight: %s\" % meta_instrument_weight + '\\n')\n","    text_file.write(\"signature_decoder: %s\" % signature_decoder + '\\n')\n","    text_file.write(\"signature_dim: %s\" % signature_dim + '\\n')\n","    text_file.write(\"signature_activation: %s\" % signature_activation + '\\n')\n","    text_file.write(\"signature_weight: %s\" % signature_weight + '\\n')\n","    text_file.write(\"composer_decoder_at_notes_output: %s\" % composer_decoder_at_notes_output + '\\n')\n","    text_file.write(\"composer_decoder_at_notes_weight: %s\" % composer_decoder_at_notes_weight + '\\n')\n","    text_file.write(\"composer_decoder_at_notes_activation: %s\" % composer_decoder_at_notes_activation + '\\n')\n","    text_file.write(\"composer_decoder_at_instrument_output: %s\" % composer_decoder_at_instrument_output + '\\n')\n","    text_file.write(\"composer_decoder_at_instrument_weight: %s\" % composer_decoder_at_instrument_weight + '\\n')\n","    text_file.write(\"composer_decoder_at_instrument_activation: %s\" % composer_decoder_at_instrument_activation+ '\\n')\n","    text_file.write(\"meta_velocity: %s\" % meta_velocity +\"\\n\")\n","    text_file.write(\"meta_velocity_activation: %s\" % meta_velocity_activation +\"\\n\")\n","    text_file.write(\"meta_velocity_weight: %s\" % meta_velocity_weight +\"\\n\")\n","    text_file.write(\"meta_held_notes: %s\" % meta_held_notes +\"\\n\")\n","    text_file.write(\"meta_held_notes_length: %s\" % meta_held_notes_length +\"\\n\")\n","    text_file.write(\"meta_held_notes_activation: %s\" % meta_held_notes_activation +\"\\n\")\n","    text_file.write(\"meta_held_notes_weight: %s\" % meta_held_notes_weight +\"\\n\")\n","    text_file.write(\"meta_next_notes: %s\" % meta_next_notes +\"\\n\")\n","    text_file.write(\"meta_next_notes_output_length: %s\" % meta_next_notes_output_length +\"\\n\")\n","    text_file.write(\"meta_next_notes_weight: %s\" % meta_next_notes_weight +\"\\n\")\n","    text_file.write(\"meta_next_notes_teacher_force: %s\" % meta_next_notes_teacher_force +\"\\n\")\n","    text_file.write(\"activation_before_splitting: %s\" % activation_before_splitting+\"\\n\")\n","    text_file.write(\"train_paths: %s\" % train_paths + '\\n')\n","    text_file.write(\"test_paths: %s\" % test_paths + '\\n')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_YgVSpMPN0Qg","colab_type":"code","outputId":"f83b8e79-904a-4f12-d448-8a1d51e48e7d","executionInfo":{"status":"ok","timestamp":1552427813602,"user_tz":300,"elapsed":16898,"user":{"displayName":"Ruizhe Zhou","photoUrl":"https://lh4.googleusercontent.com/-sBRFsLdbFZM/AAAAAAAAAAI/AAAAAAAAAAw/-KtTDHSENRY/s64/photo.jpg","userId":"01939273869007822559"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"cell_type":"code","source":["\n","# ----------------------------------------------------------------------------------------------\n","# Final preprocessing / Calculate signature vectors for set\n","# ----------------------------------------------------------------------------------------------\n","\n","total_notes = 0\n","for train_song_num in range(len(X_train)):\n","    x = X_train[train_song_num]\n","    total_notes += input_length * x.shape[0]\n","\n","print(\"Total steps (notes + silent): \", total_notes)\n","print(\"Total samples: \", total_notes // input_length)\n","\n","all_S = []\n","S_train = []\n","for train_song_num in range(len(Y_train)):\n","    Y = Y_train[train_song_num]\n","    num_samples = Y.shape[0]\n","    signature_vectors = np.zeros((num_samples, signature_vector_length))\n","    for sample in range(num_samples):\n","\n","        poly_sample = data_class.monophonic_to_khot_pianoroll(Y[sample], max_voices)\n","        if include_silent_note:\n","            poly_sample = poly_sample[:,:-1]\n","        signature = data_class.signature_from_pianoroll(poly_sample)\n","        signature_vectors[sample] = signature\n","    S_train.append(signature_vectors)\n","    all_S.extend(signature_vectors)\n","\n","all_S = np.asarray(all_S)\n","\n","mean_signature = np.mean(all_S, axis=0)\n","print(mean_signature)\n","std_signature = np.std(all_S, axis=0)\n","\n","#make sure you don't divide by zero if std is 0\n","for i, val in enumerate(std_signature):\n","    if val == 0:\n","        std_signature[i] = 1.0e-10\n","print(std_signature)\n","\n","\n","normalized_S_train = []\n","for signature_vectors in S_train:\n","    normalized_signature_vectors = (signature_vectors - mean_signature) / std_signature\n","    normalized_S_train.append(normalized_signature_vectors)\n","\n","normalized_S_test = []\n","for test_song_num in range(len(Y_test)):\n","    Y = Y_test[test_song_num]\n","    num_samples = Y.shape[0]\n","    signature_vectors = np.zeros((num_samples, signature_vector_length))\n","    for sample in range(num_samples):\n","\n","        poly_sample = data_class.monophonic_to_khot_pianoroll(Y[sample], max_voices)\n","\n","        if include_silent_note:\n","            poly_sample = poly_sample[:,:-1]\n","        signature = data_class.signature_from_pianoroll(poly_sample)\n","        signature = (signature - mean_signature) / std_signature\n","        signature_vectors[sample] = signature\n","    normalized_S_test.append(signature_vectors)\n"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Total steps (notes + silent):  1249536\n","Total samples:  19524\n","[4.63173530e-01 1.98312013e+00 6.81430547e-01 5.17546343e-01\n"," 2.96511703e-01 4.17273192e-01 7.92304548e-02 8.30373116e-02\n"," 3.67002373e-05 9.49891147e-03 2.04734979e-02 6.35571604e+00\n"," 1.62512805e+00 3.13064624e+00 1.66685912e+00]\n","[3.16043971e-01 9.52699055e-01 3.58155261e-01 1.66381767e-01\n"," 1.22771435e-01 1.38273248e-01 4.41497612e-02 8.09328972e-02\n"," 1.30047682e-03 1.22417683e-02 2.08452213e-02 4.05073434e+00\n"," 2.02128745e+00 2.28898173e+00 1.36112865e+00]\n"],"name":"stdout"}]},{"metadata":{"id":"U5kw3WsDOSM_","colab_type":"code","outputId":"2fabcee4-5cd1-4b25-efd8-f7865d95a30b","colab":{"base_uri":"https://localhost:8080/","height":23630}},"cell_type":"code","source":["\n","# ----------------------------------------------------------------------------------------------\n","# Train and test\n","# ----------------------------------------------------------------------------------------------\n","\n","# Train model\n","print('Training model...')\n","start_epoch = 0\n","if load_previous_checkpoint:\n","    start_epoch = previous_epoch\n","for e in range(start_epoch, epochs):\n","\n","    #total_switched_notes = 0\n","    total_train_loss = 0.0\n","    total_train_accuracy = 0.0\n","    total_train_meta_instrument_accuracy = 0.0\n","    total_train_meta_instrument_loss = 0.0\n","    total_train_meta_velocity_accuracy = 0.0\n","    total_train_meta_velocity_loss = 0.0\n","    total_train_meta_held_notes_accuracy = 0.0\n","    total_train_meta_held_notes_loss = 0.0\n","    total_train_meta_next_notes_accuracy = 0.0\n","    total_train_meta_next_notes_loss = 0.0\n","    total_train_composer_accuracy = 0.0\n","    total_train_composer_loss = 0.0\n","    total_train_signature_accuracy = 0.0\n","    total_train_signature_loss = 0.0\n","    total_train_notes_loss = 0.0\n","    total_train_kl_loss = 0.0\n","    total_train_composer_notes_accuracy = 0.0\n","    total_train_composer_notes_loss = 0.0\n","    total_train_composer_instrument_accuracy = 0.0\n","    total_train_composer_instrument_loss = 0.0\n","    \n","    \n","    print('Epoch ', e, 'of ', epochs, 'Epochs\\nTraining:')\n","\n","    print(\"Beta: \", beta)\n","    print(\"Epsilon std: \", epsilon_std)\n","\n","    if shuffle_train_set:\n","\n","        permutation = np.random.permutation(len(X_train))\n","\n","        train_paths = [train_paths[i] for i in permutation]\n","        X_train = [X_train[i] for i in permutation]\n","        Y_train = [Y_train[i] for i in permutation]\n","        C_train = [C_train[i] for i in permutation]\n","        I_train = [I_train[i] for i in permutation]\n","        V_train = [V_train[i] for i in permutation]\n","        D_train = [D_train[i] for i in permutation]\n","        S_train = [S_train[i] for i in permutation]\n","        normalized_S_train = [normalized_S_train[i] for i in permutation]\n","        T_train = [T_train[i] for i in permutation]\n","        \n","\n","    bar = progressbar.ProgressBar(max_value=train_set_size)\n","    for train_song_num in range(len(X_train)):\n","\n","        X = X_train[train_song_num]\n","        Y = Y_train[train_song_num]\n","        C = C_train[train_song_num] \n","        I = I_train[train_song_num]\n","        V = V_train[train_song_num]\n","        D = D_train[train_song_num]\n","        S = normalized_S_train[train_song_num]\n","\n","        T = T_train[train_song_num] #not yet used\n","\n","        #calculate history if desired\n","        if history:\n","            #don't use the history on the 0'th epoch since the encoder is not trained yet\n","            if e == 0:\n","                H = np.zeros((X.shape[0], latent_dim))\n","            else:\n","                #get the representation by feeding the inputs into the encoder\n","                encoder_input_list = vae_definition.prepare_encoder_input_list(X,I,V,D)\n","                representation_list = encoder.predict(encoder_input_list, batch_size=batch_size, verbose=False)\n","                #roll the list by one to save the representation of the last sample for each input\n","                H = np.zeros(representation_list.shape)\n","                H[1:] = representation_list[:-1]\n","        else:\n","            H = np.zeros((X.shape[0], latent_dim))\n","\n","        input_list, output_list, sample_weight = vae_definition.prepare_autoencoder_input_and_output_list(X,Y,C,I,V,D,S,H, return_sample_weight=True)\n","\n","        hist = autoencoder.fit(input_list, output_list,\n","                epochs=1,\n","                batch_size=batch_size,\n","                shuffle=False,\n","                sample_weight=sample_weight,\n","                verbose=False)\n","\n","        if reset_states:\n","            autoencoder.reset_states()\n","\n","        bar.update(train_song_num+1)\n","\n","\n","        total_train_loss += np.mean(hist.history['loss'])\n","\n","        #make sure you have installed keras=2.0.8 if you receive only one loss instead of decoder_loss_0,1,2... for each output\n","        #did not work for keras=2.1.4\n","        if meta_instrument or meta_velocity or meta_held_notes or meta_next_notes:\n","            count = 1\n","            total_train_accuracy += np.mean(hist.history['decoder_acc_' + str(count)])\n","            total_train_notes_loss += np.mean(hist.history['decoder_loss_' + str(count)])\n","            if meta_instrument:\n","                count += 1\n","                total_train_meta_instrument_accuracy += np.mean(hist.history['decoder_acc_' + str(count)])\n","                total_train_meta_instrument_loss += np.mean(hist.history['decoder_loss_' + str(count)])\n","            if meta_velocity:\n","                count += 1\n","                total_train_meta_velocity_accuracy += np.mean(hist.history['decoder_acc_' + str(count)])\n","                total_train_meta_velocity_loss += np.mean(hist.history['decoder_loss_' + str(count)])\n","            if meta_held_notes:\n","                count += 1\n","                total_train_meta_held_notes_accuracy += np.mean(hist.history['decoder_acc_' + str(count)])\n","                total_train_meta_held_notes_loss += np.mean(hist.history['decoder_loss_' + str(count)])\n","            if meta_next_notes:\n","                count += 1\n","                total_train_meta_next_notes_accuracy += np.mean(hist.history['decoder_acc_' + str(count)])\n","                total_train_meta_next_notes_loss += np.mean(hist.history['decoder_loss_' + str(count)])\n","        else:\n","            if len(hist.history.keys()) > 2:\n","                total_train_accuracy += np.mean(hist.history['decoder_acc'])\n","                total_train_notes_loss += np.mean(hist.history['decoder_loss'])\n","            else:\n","                total_train_accuracy += np.mean(hist.history['acc'])\n","                total_train_notes_loss += np.mean(hist.history['loss'])\n","\n","\n","        if include_composer_decoder:\n","\n","            total_train_composer_accuracy += np.mean(hist.history['composer_decoder_acc'])\n","            total_train_composer_loss += np.mean(hist.history['composer_decoder_loss'])\n","        if signature_decoder:\n","            total_train_signature_accuracy += np.mean(hist.history['signature_decoder_acc'])\n","            total_train_signature_loss += np.mean(hist.history['signature_decoder_loss'])\n","\n","        if composer_decoder_at_notes_output:\n","            total_train_composer_notes_accuracy += np.mean(hist.history['composer_decoder_at_notes_acc'])\n","            total_train_composer_notes_loss += np.mean(hist.history['composer_decoder_at_notes_loss'])\n","\n","        if composer_decoder_at_instrument_output:\n","            total_train_composer_instrument_accuracy += np.mean(hist.history['composer_decoder_at_instruments_acc'])\n","            total_train_composer_instrument_loss += np.mean(hist.history['composer_decoder_at_instruments_loss'])\n","            \n","\n","    total_train_loss = total_train_loss/train_set_size\n","    total_train_accuracy = total_train_accuracy/train_set_size\n","\n","    total_train_notes_loss = total_train_notes_loss/train_set_size\n","    total_train_notes_loss_array.append(total_train_notes_loss)\n","\n","    total_train_loss_array.append(total_train_loss)\n","    total_train_accuracy_array.append(total_train_accuracy)\n","\n","    if meta_instrument:\n","        train_meta_instrument_accuracy = total_train_meta_instrument_accuracy/train_set_size\n","        train_meta_instrument_loss = total_train_meta_instrument_loss/train_set_size\n","        total_train_meta_instrument_accuracy_array.append(train_meta_instrument_accuracy) \n","        total_train_meta_instrument_loss_array.append(train_meta_instrument_loss)\n","        print(\"Train instrument meta accuracy: \", train_meta_instrument_accuracy) \n","        print(\"Train instrument meta loss: \", train_meta_instrument_loss)\n","\n","    if meta_velocity:\n","        train_meta_velocity_accuracy = total_train_meta_velocity_accuracy/train_set_size\n","        train_meta_velocity_loss = total_train_meta_velocity_loss/train_set_size\n","        total_train_meta_velocity_accuracy_array.append(train_meta_velocity_accuracy) \n","        total_train_meta_velocity_loss_array.append(train_meta_velocity_loss)\n","        if combine_velocity_and_held_notes:\n","            print(\"Train velocity meta accuracy: \", train_meta_velocity_accuracy) \n","        print(\"Train velocity meta loss: \", train_meta_velocity_loss)\n","\n","    if meta_held_notes:\n","        train_meta_held_notes_accuracy = total_train_meta_held_notes_accuracy/train_set_size\n","        train_meta_held_notes_loss = total_train_meta_held_notes_loss/train_set_size\n","        total_train_meta_held_notes_accuracy_array.append(train_meta_held_notes_accuracy) \n","        total_train_meta_held_notes_loss_array.append(train_meta_held_notes_loss)\n","        print(\"Train held_notes meta accuracy: \", train_meta_held_notes_accuracy) \n","        print(\"Train held_notes meta loss: \", train_meta_held_notes_loss)\n","\n","    if meta_next_notes:\n","        train_meta_next_notes_accuracy = total_train_meta_next_notes_accuracy/train_set_size\n","        train_meta_next_notes_loss = total_train_meta_next_notes_loss/train_set_size\n","        total_train_meta_next_notes_accuracy_array.append(train_meta_next_notes_accuracy) \n","        total_train_meta_next_notes_loss_array.append(train_meta_next_notes_loss)\n","        print(\"Train next_notes meta accuracy: \", train_meta_next_notes_accuracy) \n","        print(\"Train next_notes meta loss: \", train_meta_next_notes_loss)\n","\n","    if include_composer_decoder:\n","        train_composer_accuracy = total_train_composer_accuracy/train_set_size\n","        train_composer_loss = total_train_composer_loss/train_set_size\n","        total_train_composer_accuracy_array.append(train_composer_accuracy)\n","        total_train_composer_loss_array.append(train_composer_loss)\n","        print(\"Train composer accuracy: \", train_composer_accuracy) \n","        print(\"Train composer loss: \", train_composer_loss)\n","\n","    if signature_decoder:\n","        train_signature_accuracy = total_train_signature_accuracy/train_set_size\n","        train_signature_loss = total_train_signature_loss/train_set_size\n","        total_train_signature_accuracy_array.append(train_signature_accuracy)\n","        total_train_signature_loss_array.append(train_signature_loss)\n","        #print(\"Train signature accuracy: \", train_signature_accuracy) \n","        print(\"Train signature loss: \", train_signature_loss)\n","\n","    if composer_decoder_at_notes_output:\n","        train_composer_notes_accuracy = total_train_composer_notes_accuracy/train_set_size\n","        train_composer_notes_loss = total_train_composer_notes_loss/train_set_size\n","        total_train_composer_notes_accuracy_array.append(train_composer_notes_accuracy)\n","        total_train_composer_notes_loss_array.append(train_composer_notes_loss)\n","        print(\"Train composer_notes accuracy: \", train_composer_notes_accuracy) \n","        print(\"Train composer_notes loss: \", train_composer_notes_loss)\n","\n","    if composer_decoder_at_instrument_output:\n","        train_composer_instrument_accuracy = total_train_composer_instrument_accuracy/train_set_size\n","        train_composer_instrument_loss = total_train_composer_instrument_loss/train_set_size\n","        total_train_composer_instrument_accuracy_array.append(train_composer_instrument_accuracy)\n","        total_train_composer_instrument_loss_array.append(train_composer_instrument_loss)\n","        print(\"Train composer_instrument accuracy: \", train_composer_instrument_accuracy) \n","        print(\"Train composer_instrument loss: \", train_composer_instrument_loss)\n","\n","\n","\n","    print(\"Train notes accuracy: \", total_train_accuracy)\n","    print(\"Train notes loss: \", total_train_notes_loss)\n","\n","    if beta>0:\n","        kl_loss = total_train_loss - total_train_notes_loss * 1.0\n","        if include_composer_decoder: kl_loss -= train_composer_loss * composer_weight\n","        if meta_instrument: kl_loss -= train_meta_instrument_loss * meta_instrument_weight\n","        if meta_velocity: kl_loss -= train_meta_velocity_loss * meta_velocity_weight\n","        if meta_held_notes: kl_loss -= train_meta_held_notes_loss * meta_held_notes_weight\n","        if meta_next_notes: kl_loss -= train_meta_next_notes_loss * meta_next_notes_weight\n","        if signature_decoder: kl_loss -= train_signature_loss * signature_weight\n","        if composer_decoder_at_notes_output: kl_loss -= train_composer_notes_loss * composer_decoder_at_notes_weight\n","        if composer_decoder_at_instrument_output: kl_loss -= train_composer_instrument_loss * composer_decoder_at_instrument_weight\n","        #since you get the value back weighted, scale back by dividing by beta\n","        kl_loss = kl_loss / beta\n","        total_train_kl_loss_array.append(kl_loss)\n","        print('Train KL loss: ', kl_loss)\n","\n","    print(\"Total train loss: \", total_train_loss)\n","\n","    if e % test_step is 0:\n","        test()\n","    \n","    if e% save_step is 0:\n","        print('saving model')\n","        autoencoder_save_path = model_path + 'autoencoder' + 'Epoch' + str(e) + model_filetype\n","        #autoencoder.save(autoencoder_save_path)\n","        autoencoder.save_weights(autoencoder_save_path)\n","\n","        encoder_save_path = model_path + 'encoder' + 'Epoch' + str(e) + model_filetype\n","        #encoder.save(encoder_save_path)\n","        encoder.save_weights(encoder_save_path)\n","\n","        decoder_save_path = model_path + 'decoder' + 'Epoch' + str(e) + model_filetype\n","        #decoder.save(decoder_save_path)\n","        decoder.save_weights(decoder_save_path)\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training model...\n","Epoch  0 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:11 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.33184307356261544\n","Train instrument meta loss:  2.060730731008399\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.6288669135731956\n","Train composer loss:  0.506525730047474\n","Train notes accuracy:  0.31027006411261104\n","Train notes loss:  3.595452121971655\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","saving model\n","Epoch  1 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:42 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  2 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:35 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  3 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:37 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  4 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:42 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  5 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:35 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  6 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:43 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  7 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:34 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  8 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:41 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  9 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:36 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  10 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:32 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","saving model\n","Epoch  11 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:32 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  12 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:29 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  13 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:30 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  14 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:27 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  15 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  16 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:26 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:05 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  17 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  18 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:24 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  19 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:24 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  20 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:05 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","saving model\n","Epoch  21 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  22 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:27 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  23 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:27 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  24 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  25 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:24 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  26 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  27 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:29 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  28 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  29 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:23 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:05 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  30 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","saving model\n","Epoch  31 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:23 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  32 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:23 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:05 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  33 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:23 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  34 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:23 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  35 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:21 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:05 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  36 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:22 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  37 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  38 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:25 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  39 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:26 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  40 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:28 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","saving model\n","Epoch  41 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:28 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:05 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  42 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:40 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  43 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:28 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  44 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:02:37 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:06 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  45 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:03:12 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:08 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  46 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:04:12 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:07 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  47 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:04:16 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:08 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  48 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:04:19 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:08 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  49 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:04:02 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:07 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","Epoch  50 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":["100% (180 of 180) |######################| Elapsed Time: 0:04:09 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["Train instrument meta accuracy:  0.3347222222222222\n","Train instrument meta loss:  1.1904373534340114e-07\n","Train velocity meta loss:  nan\n","Train composer accuracy:  0.5\n","Train composer loss:  1.1920930376163597e-07\n","Train notes accuracy:  0.0004269555013807904\n","Train notes loss:  1.3872184992873115e-07\n","Train KL loss:  nan\n","Total train loss:  nan\n","\n","Testing:\n"],"name":"stdout"},{"output_type":"stream","text":["100% (20 of 20) |########################| Elapsed Time: 0:00:08 ETA:  00:00:00"],"name":"stderr"},{"output_type":"stream","text":["\n","Test composer accuracy:  0.5\n","Test composer loss:  1.1920930376163597e-07\n","Test meta instrument accuracy:  0.25\n","Test meta instrument loss:  1.1920930376163597e-07\n","Test notes accuracy:  0.00022720025153830648\n","Test notes loss:  1.6181238322587886e-07\n","Test meta velocity accuracy:  0.009850344635196961\n","Test meta velocity loss:  nan\n","Test KL loss:  nan\n","Total test loss:  nan\n","--------------------------------------------------\n","saving model\n","Epoch  51 of  100 Epochs\n","Training:\n","Beta:  0.1\n","Epsilon std:  0.01\n"],"name":"stdout"},{"output_type":"stream","text":[" 55% (100 of 180) |############          | Elapsed Time: 0:02:22 ETA:   0:01:54"],"name":"stderr"}]},{"metadata":{"id":"z-UqzAvwO20C","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}